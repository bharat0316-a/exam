<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DESIGN AND ANALYSIS OF ALGORITHM</title>
    <style>
        /* ============================================================================
   ELEGANT CSS FOR ACADEMIC MARKDOWN CONVERTER
   Clean book/PDF style with white background and black text
   ============================================================================ */

* {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
}

html {
    font-size: 16px;
    -webkit-font-smoothing: antialiased;
    -moz-osx-font-smoothing: grayscale;
    scroll-behavior: smooth;
}

body {
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', sans-serif;
    line-height: 1.6;
    color: #000000;
    background: #ffffff;
    min-height: 100vh;
    overflow-x: hidden;
}

/* ============================================================================
   CONTAINER
   ============================================================================ */

.container {
    max-width: 8.5in;
    margin: 0 auto;
    padding: 40px;
    background: #ffffff;
}

/* ============================================================================
   HEADER STYLES
   ============================================================================ */

.document-header {
    text-align: center;
    margin-bottom: 40px;
    padding-bottom: 25px;
    border-bottom: 2px solid #000000;
}

.document-title {
    font-size: 32px;
    font-weight: 800;
    line-height: 1.2;
    margin-bottom: 20px;
    color: #000000;
    text-transform: uppercase;
    letter-spacing: 0.5px;
}

.document-meta {
    display: flex;
    justify-content: center;
    gap: 25px;
    margin-top: 15px;
    flex-wrap: wrap;
}

.document-meta .meta-item {
    font-size: 14px;
    color: #333333;
    font-weight: 500;
    padding: 5px 12px;
    background: #f8f8f8;
    border-radius: 4px;
    border: 1px solid #e0e0e0;
}

.document-meta .meta-item strong {
    color: #000000;
    font-weight: 600;
    margin-right: 4px;
}

/* ============================================================================
   TABLE OF CONTENTS
   ============================================================================ */

.table-of-contents {
    margin-bottom: 40px;
    padding: 20px;
    background: #f9f9f9;
    border-left: 4px solid #000000;
    border-radius: 0 4px 4px 0;
}

.toc-title {
    font-size: 18px;
    font-weight: 700;
    color: #000000;
    margin-bottom: 15px;
    padding-bottom: 8px;
    border-bottom: 1px solid #cccccc;
}

.toc-list {
    list-style: none;
    padding-left: 0;
}

.toc-list li {
    margin-bottom: 8px;
    padding-left: 0;
    position: relative;
}

.toc-list li.toc-indent {
    padding-left: 20px;
}

.toc-list a {
    color: #333333;
    text-decoration: none;
    font-size: 15px;
    transition: color 0.2s ease;
    display: block;
    padding: 4px 0;
}

.toc-list a:hover {
    color: #000000;
    text-decoration: underline;
}

/* ============================================================================
   CONTENT AREA
   ============================================================================ */

.content {
    padding: 20px 0;
}

/* ============================================================================
   SECTION STYLES
   ============================================================================ */

.content-section {
    margin-bottom: 40px;
    page-break-inside: avoid;
}

.section-heading {
    font-weight: 700;
    color: #000000;
    margin-bottom: 20px;
    padding-bottom: 10px;
    border-bottom: 1px solid #e0e0e0;
}

h1.section-heading {
    font-size: 26px;
    border-bottom: 2px solid #000000;
}

h2.section-heading {
    font-size: 22px;
}

h3.section-heading {
    font-size: 18px;
}

h4.section-heading {
    font-size: 16px;
}

h5.section-heading, h6.section-heading {
    font-size: 15px;
}

/* ============================================================================
   PARAGRAPH STYLES
   ============================================================================ */

.paragraph {
    font-size: 15px;
    color: #333333;
    line-height: 1.7;
    margin-bottom: 20px;
    text-align: justify;
}

.paragraph strong {
    color: #000000;
    font-weight: 700;
}

.paragraph em {
    font-style: italic;
}

.paragraph code {
    font-family: 'Courier New', monospace;
    background: #f5f5f5;
    padding: 2px 6px;
    border-radius: 3px;
    font-size: 14px;
    border: 1px solid #e0e0e0;
}

/* ============================================================================
   LIST STYLES
   ============================================================================ */

.content-list {
    margin-left: 20px;
    margin-bottom: 20px;
}

.content-list ul, .content-list ol {
    margin-left: 20px;
    margin-top: 10px;
}

.content-list li {
    margin-bottom: 10px;
    color: #333333;
    font-size: 15px;
    line-height: 1.6;
}

.content-list li strong {
    color: #000000;
    font-weight: 700;
}

.content-list li code {
    font-family: 'Courier New', monospace;
    background: #f5f5f5;
    padding: 2px 6px;
    border-radius: 3px;
    font-size: 14px;
    border: 1px solid #e0e0e0;
}

/* ============================================================================
   CODE BLOCK STYLES
   ============================================================================ */

.code-block {
    margin: 25px 0;
    position: relative;
}

.code-block pre {
    margin: 0;
    padding: 0;
    border-radius: 6px;
    overflow: hidden;
    border: 1px solid #e0e0e0;
    background: #f8f9fa !important;
}

.code-block code {
    font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
    font-size: 14px;
    line-height: 1.5;
    display: block;
    padding: 20px;
    overflow-x: auto;
    color: #333333;
}

.copy-button {
    position: absolute;
    top: 10px;
    right: 10px;
    padding: 6px 12px;
    background: #000000;
    color: #ffffff;
    border: none;
    border-radius: 4px;
    font-size: 12px;
    cursor: pointer;
    opacity: 0.7;
    transition: opacity 0.2s ease;
    z-index: 10;
}

.copy-button:hover {
    opacity: 1;
}

.copy-button.copied {
    background: #2e7d32;
    opacity: 1;
}

/* Prism.js theme adjustments */
.token.comment, .token.prolog, .token.doctype, .token.cdata {
    color: #6a737d;
}

.token.punctuation {
    color: #333333;
}

.token.property, .token.tag, .token.boolean, .token.number, .token.constant, .token.symbol, .token.deleted {
    color: #005cc5;
}

.token.selector, .token.attr-name, .token.string, .token.char, .token.builtin, .token.inserted {
    color: #032f62;
}

.token.operator, .token.entity, .token.url, .language-css .token.string, .style .token.string {
    color: #d73a49;
}

.token.atrule, .token.attr-value, .token.keyword {
    color: #d73a49;
    font-weight: bold;
}

.token.function, .token.class-name {
    color: #6f42c1;
}

.token.regex, .token.important, .token.variable {
    color: #e36209;
}

/* ============================================================================
   SPECIAL CONTENT BLOCKS
   ============================================================================ */

.special-block {
    margin: 25px 0;
    padding: 20px;
    border-radius: 6px;
    border-left: 4px solid #000000;
    background: #f9f9f9;
}

.special-block.reference {
    border-left-color: #2e7d32;
}

.special-block.example {
    border-left-color: #1565c0;
}

.special-block.syntax {
    border-left-color: #6a1b9a;
}

.special-block.functions {
    border-left-color: #c62828;
}

.special-label {
    font-size: 16px;
    font-weight: 700;
    color: #000000;
    margin-bottom: 12px;
    display: flex;
    align-items: center;
}

.special-label::before {
    content: "";
    display: inline-block;
    width: 12px;
    height: 12px;
    background: currentColor;
    margin-right: 10px;
    border-radius: 2px;
}

.special-content {
    font-size: 15px;
    color: #333333;
    line-height: 1.6;
}

.special-content .content-line {
    margin-bottom: 8px;
}

/* ============================================================================
   HORIZONTAL RULE
   ============================================================================ */

.content-hr {
    border: none;
    height: 1px;
    background: linear-gradient(to right, transparent, #cccccc, transparent);
    margin: 40px 0;
}

/* ============================================================================
   FOOTER
   ============================================================================ */

.document-footer {
    margin-top: 60px;
    padding-top: 25px;
    border-top: 1px solid #cccccc;
    text-align: center;
}

.footer-content p {
    font-size: 14px;
    color: #666666;
    margin-bottom: 8px;
}

.document-stats {
    font-size: 13px !important;
    color: #888888 !important;
    font-style: italic;
}

/* ============================================================================
   RESPONSIVE DESIGN - MOBILE
   ============================================================================ */

@media (max-width: 900px) {
    .container {
        padding: 30px;
        max-width: 100%;
    }
    
    .document-title {
        font-size: 28px;
    }
    
    .document-meta {
        gap: 15px;
    }
    
    h1.section-heading {
        font-size: 24px;
    }
    
    h2.section-heading {
        font-size: 20px;
    }
    
    .code-block code {
        font-size: 13px;
        padding: 15px;
    }
}

@media (max-width: 768px) {
    .container {
        padding: 20px;
    }
    
    .document-title {
        font-size: 24px;
    }
    
    .document-meta {
        flex-direction: column;
        gap: 8px;
        align-items: center;
    }
    
    .document-meta .meta-item {
        width: 100%;
        max-width: 300px;
        text-align: center;
    }
    
    .table-of-contents {
        padding: 15px;
    }
    
    .toc-title {
        font-size: 16px;
    }
    
    .toc-list a {
        font-size: 14px;
    }
    
    h1.section-heading {
        font-size: 22px;
    }
    
    h2.section-heading {
        font-size: 18px;
    }
    
    h3.section-heading {
        font-size: 16px;
    }
    
    .paragraph {
        font-size: 14px;
    }
    
    .content-list li {
        font-size: 14px;
    }
    
    .special-block {
        padding: 15px;
    }
    
    .special-content {
        font-size: 14px;
    }
    
    .code-block code {
        font-size: 12px;
        padding: 12px;
    }
    
    .copy-button {
        font-size: 11px;
        padding: 5px 10px;
    }
}

@media (max-width: 480px) {
    .container {
        padding: 15px;
    }
    
    .document-title {
        font-size: 20px;
    }
    
    .document-header {
        margin-bottom: 30px;
        padding-bottom: 20px;
    }
    
    h1.section-heading {
        font-size: 20px;
    }
    
    h2.section-heading {
        font-size: 17px;
    }
    
    .paragraph {
        font-size: 13px;
    }
    
    .content-list {
        margin-left: 15px;
    }
    
    .content-list li {
        font-size: 13px;
    }
    
    .code-block {
        margin: 20px -15px;
        border-radius: 0;
    }
    
    .code-block pre {
        border-radius: 0;
        border-left: none;
        border-right: none;
    }
    
    .special-block {
        margin: 20px -15px;
        border-radius: 0;
        border-left: none;
        border-right: 4px solid #000000;
    }
}

/* ============================================================================
   PRINT STYLES
   ============================================================================ */

@media print {
    @page {
        margin: 0.5in;
        size: letter;
    }
    
    body {
        font-size: 12pt;
        line-height: 1.5;
        background: white !important;
        color: black !important;
    }
    
    .container {
        max-width: 100%;
        padding: 0;
        margin: 0;
    }
    
    .document-header {
        border-bottom: 1pt solid black;
        margin-bottom: 0.3in;
        padding-bottom: 0.2in;
    }
    
    .document-title {
        font-size: 16pt;
        margin-bottom: 0.1in;
    }
    
    .document-meta .meta-item {
        font-size: 9pt;
        border: 0.5pt solid #cccccc;
        background: #ffffff;
    }
    
    .table-of-contents {
        border-left: 2pt solid black;
        background: #ffffff !important;
        margin-bottom: 0.3in;
    }
    
    .toc-title {
        font-size: 11pt;
        border-bottom: 0.5pt solid #cccccc;
    }
    
    .toc-list a {
        font-size: 10pt;
        color: #000000;
    }
    
    .content-section {
        margin-bottom: 0.3in;
        page-break-inside: avoid;
    }
    
    .section-heading {
        font-weight: 700;
        color: #000000;
        border-bottom: 0.5pt solid #cccccc;
        page-break-after: avoid;
    }
    
    h1.section-heading {
        font-size: 14pt;
        border-bottom: 1pt solid black;
    }
    
    h2.section-heading {
        font-size: 12pt;
    }
    
    h3.section-heading {
        font-size: 11pt;
    }
    
    .paragraph {
        font-size: 11pt;
        text-align: left;
        margin-bottom: 0.15in;
    }
    
    .content-list {
        margin-left: 0.2in;
        margin-bottom: 0.15in;
    }
    
    .content-list li {
        font-size: 11pt;
        margin-bottom: 0.05in;
    }
    
    .code-block {
        margin: 0.2in 0;
        break-inside: avoid;
    }
    
    .code-block pre {
        border: 0.5pt solid #cccccc;
        background: #ffffff !important;
    }
    
    .code-block code {
        font-size: 9pt;
        padding: 0.15in;
        color: #000000;
    }
    
    /* Hide copy buttons in print */
    .copy-button {
        display: none !important;
    }
    
    .special-block {
        margin: 0.2in 0;
        padding: 0.15in;
        border-left: 2pt solid #000000;
        background: #ffffff !important;
        break-inside: avoid;
    }
    
    .special-label {
        font-size: 11pt;
    }
    
    .special-content {
        font-size: 11pt;
    }
    
    .content-hr {
        height: 0.5pt;
        margin: 0.3in 0;
    }
    
    .document-footer {
        margin-top: 0.3in;
        padding-top: 0.1in;
        border-top: 0.5pt solid #cccccc;
    }
    
    .footer-content p {
        font-size: 9pt;
        color: #666666;
    }
    
    /* Remove all transitions, shadows, and backgrounds for print */
    * {
        box-shadow: none !important;
        transition: none !important;
    }
    
    /* Ensure proper page breaks */
    .content-section, .special-block, .code-block {
        page-break-inside: avoid;
    }
    
    h1, h2 {
        page-break-after: avoid;
    }
    
    /* No URLs in print */
    a[href]::after {
        content: " (" attr(href) ")";
        font-size: 9pt;
        color: #666666;
    }
    
    a[href^="#"]::after {
        content: "";
    }
}

/* ============================================================================
   UTILITY CLASSES
   ============================================================================ */

::selection {
    background: rgba(0, 0, 0, 0.1);
    color: #000000;
}

/* Hide scrollbar for print */
@media print {
    ::-webkit-scrollbar {
        display: none;
    }
}

/* Focus styles for accessibility */
:focus {
    outline: 2px solid #000000;
    outline-offset: 2px;
}

:focus:not(:focus-visible) {
    outline: none;
}

/* Improve dark mode compatibility */
@media (prefers-color-scheme: dark) {
    .container, body {
        background: #ffffff !important;
        color: #000000 !important;
    }
}
    </style>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css">
</head>
<body>
    <div class="container">
        
        <header class="document-header">
            <h1 class="document-title">DESIGN AND ANALYSIS OF ALGORITHM</h1>
            <div class="document-meta"><div class="meta-item"><strong>Unit:</strong> **Unit 1: Introduction to Design and Analysis of Algorithms**</div></div>
        </header>
        
        
        <nav class="table-of-contents">
            <h2 class="toc-title">Table of Contents</h2>
            <ul class="toc-list">
                
            <li class="">
                <a href="#unit-1-introduction-to-design-and-analysis-of-algorithms"><strong>Unit 1: Introduction to Design and Analysis of Algorithms</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#1-what-is-an-algorithm"><strong>1. What is an Algorithm?</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#2-fundamentals-of-algorithmic-problem-solving"><strong>2. Fundamentals of Algorithmic Problem Solving</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#3-fundamentals-of-the-analysis-of-algorithmic-efficiency"><strong>3. Fundamentals of the Analysis of Algorithmic Efficiency</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#4-analysis-framework"><strong>4. Analysis Framework</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#5-measuring-the-input-size"><strong>5. Measuring the Input Size</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#6-units-for-measuring-running-time"><strong>6. Units for Measuring Running Time</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#7-orders-of-growth"><strong>7. Orders of Growth</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#8-worst-case-best-case-and-average-case-efficiencies"><strong>8. Worst-case, Best-case and Average-case Efficiencies</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#9-asymptotic-notations-and-basic-efficiency-classes"><strong>9. Asymptotic Notations and Basic Efficiency Classes</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#10-mathematical-analysis-of-non-recursive-algorithms"><strong>10. Mathematical Analysis of Non-Recursive Algorithms</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#11-mathematical-analysis-of-recursive-algorithms"><strong>11. Mathematical Analysis of Recursive Algorithms</strong></a>
            </li>
            

            <li class="">
                <a href="#unit-2-brute-force-and-exhaustive-search"><strong>Unit 2: Brute Force and Exhaustive Search</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#1-introduction-to-brute-force-approach"><strong>1. Introduction to Brute Force Approach</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#2-selection-sort"><strong>2. Selection Sort</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#3-bubble-sort"><strong>3. Bubble Sort</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#4-sequential-search"><strong>4. Sequential Search</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#5-exhaustive-search"><strong>5. Exhaustive Search</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#6-traveling-salesman-problem-tsp"><strong>6. Traveling Salesman Problem (TSP)</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#7-knapsack-problem"><strong>7. Knapsack Problem</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#8-depth-first-search-dfs"><strong>8. Depth First Search (DFS)</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#9-breadth-first-search-bfs"><strong>9. Breadth First Search (BFS)</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#summary-of-brute-force-techniques"><strong>Summary of Brute Force Techniques</strong></a>
            </li>
            

            <li class="">
                <a href="#unit-3-decrease-and-conquer-and-divide-and-conquer"><strong>Unit 3: Decrease-and-Conquer and Divide-and-Conquer</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#1-decrease-and-conquer-introduction"><strong>1. Decrease-and-Conquer: Introduction</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#2-insertion-sort"><strong>2. Insertion Sort</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#3-topological-sorting"><strong>3. Topological Sorting</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#4-divide-and-conquer-introduction"><strong>4. Divide-and-Conquer: Introduction</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#5-merge-sort"><strong>5. Merge Sort</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#6-quick-sort"><strong>6. Quick Sort</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#7-binary-search"><strong>7. Binary Search</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#8-binary-tree-traversals-and-related-properties"><strong>8. Binary Tree Traversals and Related Properties</strong></a>
            </li>
            

            <li class="">
                <a href="#unit-4-greedy-technique-and-complexity-theory"><strong>Unit 4: Greedy Technique and Complexity Theory</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#1-greedy-technique-introduction"><strong>1. Greedy Technique: Introduction</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#2-prims-algorithm"><strong>2. Prim's Algorithm</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#3-kruskals-algorithm"><strong>3. Kruskal's Algorithm</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#4-dijkstras-algorithm"><strong>4. Dijkstra's Algorithm</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#5-lower-bound-arguments"><strong>5. Lower-Bound Arguments</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#6-decision-trees"><strong>6. Decision Trees</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#7-p-problems"><strong>7. P Problems</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#8-np-problems"><strong>8. NP Problems</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#9-np-complete-problems"><strong>9. NP-Complete Problems</strong></a>
            </li>
            

            <li class="toc-indent">
                <a href="#10-challenges-of-numerical-algorithms"><strong>10. Challenges of Numerical Algorithms</strong></a>
            </li>
            
            </ul>
        </nav>
        
        <main class="content">
            
            <section class="content-section" id="unit-1-introduction-to-design-and-analysis-of-algorithms">
                <h1 class="section-heading"><strong>Unit 1: Introduction to Design and Analysis of Algorithms</strong></h1>
            
</section>

            <section class="content-section" id="1-what-is-an-algorithm">
                <h2 class="section-heading"><strong>1. What is an Algorithm?</strong></h2>
            
</section>

            <section class="content-section" id="meaning-concept">
                <h3 class="section-heading"><strong>Meaning / Concept</strong></h3>
            
<p class="paragraph">An <strong>algorithm</strong> is a step-by-step, unambiguous, finite, and effective procedure for solving a well-defined computational problem. It takes zero or more inputs, produces at least one output, and terminates after a finite number of steps. In essence, it is a recipe or a precise set of instructions to accomplish a specific task.</p>
<p class="paragraph"><strong>Key Idea</strong>: An algorithm must be clear, correct, and efficient enough to be implemented as a computer program.</p>
</section>

            <section class="content-section" id="formal-definition">
                <h3 class="section-heading"><strong>Formal Definition</strong></h3>
            
<p class="paragraph">According to <strong>Cormen et al.</strong>, an algorithm is any well-defined computational procedure that takes some value, or set of values, as <strong>input</strong> and produces some value, or set of values, as <strong>output</strong>. It is a tool for solving a well-specified computational problem.</p>
<p class="paragraph"><strong>Levitin</strong> defines an algorithm as a sequence of unambiguous instructions for solving a problem, i.e., for obtaining a required output for any legitimate input in a finite amount of time.</p>
</section>

            <section class="content-section" id="need-purpose-applications">
                <h3 class="section-heading"><strong>Need / Purpose / Applications</strong></h3>
            
<ul class="content-list"><li><strong>Purpose</strong>: To provide a clear, mechanical process for problem-solving that can be automated using a computer.</li>
<li><strong>Need</strong>: Without algorithms, computing would be ad-hoc and inefficient. They are fundamental to all areas of computer science.</li>
<li><strong>Applications</strong>: Sorting data, searching databases, routing networks, cryptography, graphics rendering, artificial intelligence, and virtually every software application.</li></ul>
</section>

            <section class="content-section" id="algorithm-step-by-step">
                <h3 class="section-heading"><strong>Algorithm (Step-by-Step)</strong></h3>
            
<ol class="content-list"><li><strong>Problem Statement</strong>: Define what needs to be solved.</li>
<li><strong>Input</strong>: Specify the data given.</li>
<li><strong>Output</strong>: Specify the expected result.</li>
<li><strong>Steps</strong>: A finite sequence of precise instructions.</li>
<li><strong>Termination</strong>: Guarantee that the process ends.</li></ol>
<p class="paragraph">While there is no single universal format, a typical algorithm description includes:</p>

            <div class="code-block">
                <pre><code class="language-text">Algorithm MaxElement(A[0..n-1])
// Input: An array A of n comparable elements
// Output: The value of the largest element in A
maxval ← A[0]
for i ← 1 to n-1 do
    if A[i] &gt; maxval
        maxval ← A[i]
return maxval</code></pre>
            </div>
            
<p class="paragraph"><strong>Example Structure for "Find Maximum"</strong>:</p>
</section>

            <section class="content-section" id="explanation-of-the-algorithm">
                <h3 class="section-heading"><strong>Explanation of the Algorithm</strong></h3>
            
<p class="paragraph">The above algorithm (MaxElement) initializes <code>maxval</code> to the first element. It then iterates through the remaining elements. If it finds an element larger than the current <code>maxval</code>, it updates <code>maxval</code>. After checking all elements, it returns the largest value found.</p>
</section>

            <section class="content-section" id="example-problem-with-working-steps">
                <h3 class="section-heading"><strong>Example Problem with Working Steps</strong></h3>
            
<p class="paragraph"><strong>Problem</strong>: Find the maximum of [5, 2, 9, 1, 7].</p>
<ol class="content-list"><li><code>maxval = A[0] = 5</code></li>
<li><code>i = 1</code>: A[1]=2, 2 > 5? <strong>No</strong>. <code>maxval</code> stays 5.</li>
<li><code>i = 2</code>: A[2]=9, 9 > 5? <strong>Yes</strong>. <code>maxval = 9</code>.</li>
<li><code>i = 3</code>: A[3]=1, 1 > 9? <strong>No</strong>. <code>maxval</code> stays 9.</li>
<li><code>i = 4</code>: A[4]=7, 7 > 9? <strong>No</strong>. <code>maxval</code> stays 9.</li>
<li><strong>Return</strong> <code>maxval = 9</code>.</li></ol>
<p class="paragraph"><strong>Steps</strong>:</p>
</section>

            <section class="content-section" id="time-complexity">
                <h3 class="section-heading"><strong>Time Complexity</strong></h3>
            
<ul class="content-list"><li><strong>Best Case</strong>: O(n) – Still must check each element once in a standard implementation.</li>
<li><strong>Average Case</strong>: Θ(n)</li>
<li><strong>Worst Case</strong>: O(n)</li></ul>
<p class="paragraph"><em>(For this specific sequential scan, all cases are linear in the number of elements.)</em></p>
</section>

            <section class="content-section" id="space-complexity">
                <h3 class="section-heading"><strong>Space Complexity</strong></h3>
            
<p class="paragraph">O(1) – <strong>Constant space</strong>. Only a fixed number of variables (<code>maxval</code>, <code>i</code>) are used, regardless of input size <code>n</code>.</p>
</section>

            <section class="content-section" id="functions-operations-involved">
                <h3 class="section-heading"><strong>Functions / Operations Involved</strong></h3>
            
<ul class="content-list"><li><strong>Assignment</strong> (<code>←</code>)</li>
<li><strong>Comparison</strong> (<code>></code>)</li>
<li><strong>Iteration</strong> (<code>for</code> loop)</li>
<li><strong>Return</strong> operation</li></ul>
</section>

            <section class="content-section" id="characteristics-properties">
                <h3 class="section-heading"><strong>Characteristics / Properties</strong></h3>
            
<ol class="content-list"><li><strong>Input</strong>: Zero or more well-defined inputs.</li>
<li><strong>Output</strong>: At least one well-defined output.</li>
<li><strong>Definiteness</strong>: Each step is clear and unambiguous.</li>
<li><strong>Finiteness</strong>: Terminates after a finite number of steps.</li>
<li><strong>Effectiveness</strong>: Each step is basic enough to be performed exactly and in finite time. (Also referred to as <strong>Feasibility</strong>).</li></ol>
<p class="paragraph">As per <strong>Levitin</strong> and <strong>Sahni</strong>, an algorithm must have:</p>
</section>

            <section class="content-section" id="types-variants">
                <h3 class="section-heading"><strong>Types / Variants</strong></h3>
            
<ul class="content-list"><li><strong>Design Paradigm</strong>: Brute Force, Divide and Conquer, Decrease and Conquer, Dynamic Programming, Greedy, Backtracking.</li>
<li><strong>Problem Type</strong>: Sorting, Searching, Numerical, String Processing, Graph, Geometric.</li>
<li><strong>Implementation</strong>: Recursive vs. Iterative.</li></ul>
<p class="paragraph">Algorithms are broadly classified by:</p>
</section>

            <section class="content-section" id="methods-techniques-used">
                <h3 class="section-heading"><strong>Methods / Techniques Used</strong></h3>
            
<ol class="content-list"><li><strong>Natural Language</strong> (prone to ambiguity)</li>
<li><strong>Flowcharts</strong> (graphical representation)</li>
<li><strong>Pseudocode</strong> (structured English-like notation) – Most common in textbooks.</li>
<li><strong>Programming Language</strong> (actual code).</li></ol>
<p class="paragraph">Techniques for expressing an algorithm:</p>
</section>

            <section class="content-section" id="advantages">
                <h3 class="section-heading"><strong>Advantages</strong></h3>
            
<ul class="content-list"><li>Provides a clear, reproducible solution plan.</li>
<li>Allows analysis of correctness and efficiency before implementation.</li>
<li>Forms the blueprint for program development.</li>
<li>Enables communication of ideas among programmers.</li></ul>
</section>

            <section class="content-section" id="limitations">
                <h3 class="section-heading"><strong>Limitations</strong></h3>
            
<ul class="content-list"><li>A correct algorithm does not guarantee an efficient program if poorly implemented.</li>
<li>Designing an optimal algorithm for complex problems can be extremely difficult.</li>
<li>The same problem can often be solved by multiple algorithms with different trade-offs.</li></ul>
</section>

            <section class="content-section" id="real-world-usage-examples">
                <h3 class="section-heading"><strong>Real-World Usage Examples</strong></h3>
            
<ul class="content-list"><li><strong>Google Search</strong>: Uses the <strong>PageRank</strong> algorithm to rank web pages.</li>
<li><strong>GPS Navigation</strong>: Uses <strong>Dijkstra's</strong> or <strong>A* algorithm</strong> for shortest path.</li>
<li><strong>E-commerce</strong>: <strong>Recommendation algorithms</strong> suggest products.</li>
<li><strong>Banking</strong>: <strong>Sorting algorithms</strong> (like Merge Sort) process transactions.</li></ul>
<hr class="content-hr">
</section>

            <section class="content-section" id="2-fundamentals-of-algorithmic-problem-solving">
                <h2 class="section-heading"><strong>2. Fundamentals of Algorithmic Problem Solving</strong></h2>
            
</section>

            <section class="content-section" id="meaning-concept">
                <h3 class="section-heading"><strong>Meaning / Concept</strong></h3>
            
<p class="paragraph">This refers to the systematic process of designing an algorithm to solve a given computational problem. It involves understanding the problem, designing a solution, analyzing its efficiency, and implementing/testing it.</p>
</section>

            <section class="content-section" id="sequence-of-steps-levitin-sridhar">
                <h3 class="section-heading"><strong>Sequence of Steps (Levitin & Sridhar)</strong></h3>
            
<ol class="content-list"><li><strong>Understanding the Problem</strong>:</li></ol>
<p class="paragraph">- Read the problem statement carefully.
   - Identify inputs, outputs, and constraints.
   - Ask questions to clarify ambiguities.</p>
<ol class="content-list"><li><strong>Deciding on Computational Means</strong>:</li></ol>
<p class="paragraph">- Choose the computing device/model (e.g., sequential RAM model).
   - Determine the required precision (exact vs. approximate algorithm).</p>
<ol class="content-list"><li><strong>Choosing between Exact and Approximate Problem Solving</strong>:</li></ol>
<p class="paragraph">- Some problems are only feasibly solved by approximate algorithms (e.g., NP-Hard problems).</p>
<ol class="content-list"><li><strong>Choosing Appropriate Data Structures</strong>.</li></ol>
<ol class="content-list"><li><strong>Algorithm Design Technique</strong>:</li></ol>
<p class="paragraph">- Select a general strategy (e.g., Divide and Conquer, Greedy, Dynamic Programming).</p>
<ol class="content-list"><li><strong>Designing the Algorithm</strong>:</li></ol>
<p class="paragraph">- Write a clear, precise pseudocode.</p>
<ol class="content-list"><li><strong>Proving Correctness</strong>:</li></ol>
<p class="paragraph">- Use mathematical reasoning to prove the algorithm yields the correct output for all valid inputs.</p>
<ol class="content-list"><li><strong>Analyzing the Algorithm</strong>:</li></ol>
<p class="paragraph">- Analyze time and space efficiency.
   - Find asymptotic complexity (Big O, Theta, Omega).</p>
<ol class="content-list"><li><strong>Coding the Algorithm</strong>:</li></ol>
<p class="paragraph">- Implement in a programming language.
   - Consider implementation-level details.</p>
</section>

            <section class="content-section" id="importance">
                <h3 class="section-heading"><strong>Importance</strong></h3>
            
<p class="paragraph">This structured approach prevents haphazard coding, ensures correctness, and leads to efficient solutions.</p>
<hr class="content-hr">
</section>

            <section class="content-section" id="3-fundamentals-of-the-analysis-of-algorithmic-efficiency">
                <h2 class="section-heading"><strong>3. Fundamentals of the Analysis of Algorithmic Efficiency</strong></h2>
            
</section>

            <section class="content-section" id="meaning-concept">
                <h3 class="section-heading"><strong>Meaning / Concept</strong></h3>
            
<p class="paragraph">Algorithmic efficiency analysis is the process of determining the amount of resources (time and memory) an algorithm requires. The primary goal is to compare algorithms independently of programming language, compiler, or hardware.</p>
</section>

            <section class="content-section" id="two-kinds-of-efficiency">
                <h3 class="section-heading"><strong>Two Kinds of Efficiency</strong>:</h3>
            
<ol class="content-list"><li><strong>Time Efficiency (Time Complexity)</strong>: How fast an algorithm runs.</li>
<li><strong>Space Efficiency (Space Complexity)</strong>: How much extra memory it uses.</li></ol>
</section>

            <section class="content-section" id="why-analyze">
                <h3 class="section-heading"><strong>Why Analyze?</strong></h3>
            
<ul class="content-list"><li>To choose the best algorithm among several for a given problem.</li>
<li>To predict algorithm performance on large inputs.</li>
<li>To identify bottlenecks and optimize code.</li></ul>
<hr class="content-hr">
</section>

            <section class="content-section" id="4-analysis-framework">
                <h2 class="section-heading"><strong>4. Analysis Framework</strong></h2>
            
</section>

            <section class="content-section" id="meaning-concept">
                <h3 class="section-heading"><strong>Meaning / Concept</strong></h3>
            
<p class="paragraph">A systematic model for analyzing an algorithm's resource consumption. The standard framework uses the <strong>Random Access Machine (RAM) model</strong>.</p>
<ul class="content-list"><li>Instructions are executed one after another (sequential, not parallel).</li>
<li>Each basic operation (assign, compare, arithmetic, etc.) takes <strong>one unit of time</strong>.</li>
<li>Each memory access takes one unit of time.</li>
<li>Memory is unlimited (abstracts away memory hierarchy).</li></ul>
<p class="paragraph"><strong>RAM Model Assumptions (Cormen, Leiserson, Rivest, Stein)</strong>:</p>
<hr class="content-hr">
</section>

            <section class="content-section" id="5-measuring-the-input-size">
                <h2 class="section-heading"><strong>5. Measuring the Input Size</strong></h2>
            
<ul class="content-list"><li><strong>Example 1</strong>: For sorting, <code>n</code> = number of items to sort.</li>
<li><strong>Example 2</strong>: For multiplying two integers, <code>n</code> = number of digits/bit-length.</li>
<li><strong>Example 3</strong>: For a graph algorithm, <code>n</code> = number of vertices and/or edges.</li></ul>
<p class="paragraph">The <strong>input size</strong> (<code>n</code>) is the parameter that most dominantly impacts the resource usage.</p>
<p class="paragraph"><strong>Levitin</strong> emphasizes that the measure should be chosen logically based on the problem.</p>
<hr class="content-hr">
</section>

            <section class="content-section" id="6-units-for-measuring-running-time">
                <h2 class="section-heading"><strong>6. Units for Measuring Running Time</strong></h2>
            
<p class="paragraph">We do <strong>not</strong> measure in seconds/minutes as they are machine-dependent.
Two main approaches:</p>
<ol class="content-list"><li><strong>Count the Number of Times the Algorithm's Basic Operation is Executed</strong>.</li></ol>
<p class="paragraph">- <strong>Basic Operation</strong>: The most costly, frequently executed operation (e.g., comparison in sorting, multiplication in matrix operations).
   - We express the count as a function of input size <code>n</code>: <code>C(n)</code>.</p>
<ol class="content-list"><li><strong>Count the Number of Steps (a uniform cost model)</strong>.</li></ol>
<p class="paragraph">- Each line of pseudocode corresponds to a step with a constant cost.</p>
<hr class="content-hr">
</section>

            <section class="content-section" id="7-orders-of-growth">
                <h2 class="section-heading"><strong>7. Orders of Growth</strong></h2>
            
<p class="paragraph">The <strong>order of growth</strong> of an algorithm's running time is its most relevant efficiency characteristic. It focuses on how <code>C(n)</code> increases as <code>n → ∞</code>.</p>
<ul class="content-list"><li><strong>Constant</strong>: <code>1</code></li>
<li><strong>Logarithmic</strong>: <code>log n</code></li>
<li><strong>Linear</strong>: <code>n</code></li>
<li><strong>Linearithmic (n log n)</strong>: <code>n log n</code></li>
<li><strong>Quadratic</strong>: <code>n²</code></li>
<li><strong>Cubic</strong>: <code>n³</code></li>
<li><strong>Exponential</strong>: <code>2ⁿ</code>, <code>n!</code></li></ul>
<p class="paragraph"><strong>Common Orders of Growth (from slowest to fastest)</strong>:</p>
<p class="paragraph"><strong>Why it Matters</strong>: For large <code>n</code>, only the order of growth matters. An O(n) algorithm will eventually outperform an O(n²) algorithm, regardless of constant factors.</p>
<hr class="content-hr">
</section>

            <section class="content-section" id="8-worst-case-best-case-and-average-case-efficiencies">
                <h2 class="section-heading"><strong>8. Worst-case, Best-case and Average-case Efficiencies</strong></h2>
            
<p class="paragraph">An algorithm's performance can vary for different inputs of the same size.</p>
<ol class="content-list"><li><strong>Worst-case Efficiency</strong>: The <strong>maximum</strong> number of steps the algorithm takes for <strong>any</strong> input of size <code>n</code>.</li></ol>
<p class="paragraph">- <strong>Importance</strong>: Gives a guarantee on upper performance bound. Crucial for real-time systems.</p>
<ol class="content-list"><li><strong>Best-case Efficiency</strong>: The <strong>minimum</strong> number of steps for <strong>any</strong> input of size <code>n</code>.</li></ol>
<p class="paragraph">- <strong>Importance</strong>: Mostly of theoretical interest; not a reliable measure.</p>
<ol class="content-list"><li><strong>Average-case Efficiency</strong>: The <strong>average</strong> number of steps taken over <strong>all possible</strong> inputs of size <code>n</code>.</li></ol>
<p class="paragraph">- <strong>Importance</strong>: Provides expected performance, but requires knowing the probability distribution of inputs, which is often difficult.</p>
<ul class="content-list"><li>Search for a key <code>K</code> in an array <code>A[0..n-1]</code>.</li>
<li><strong>Basic Operation</strong>: Comparison <code>A[i] == K</code>.</li>
<li><strong>Worst-case</strong>: <code>K</code> is not present or is the last element → <code>n</code> comparisons → <strong>O(n)</strong>.</li>
<li><strong>Best-case</strong>: <code>K</code> is the first element → <code>1</code> comparison → <strong>Ω(1)</strong>.</li>
<li><strong>Average-case</strong>: Assuming <code>K</code> is present at each position with equal probability <code>1/n</code>. Average comparisons = <code>(1+2+...+n)/n = (n+1)/2</code> → <strong>Θ(n)</strong>.</li></ul>
<p class="paragraph"><strong>Example (Sequential Search)</strong>:</p>
<hr class="content-hr">
</section>

            <section class="content-section" id="9-asymptotic-notations-and-basic-efficiency-classes">
                <h2 class="section-heading"><strong>9. Asymptotic Notations and Basic Efficiency Classes</strong></h2>
            
<p class="paragraph">Asymptotic notations are mathematical tools to describe the <strong>order of growth</strong> of functions, ignoring constant factors and lower-order terms.</p>
</section>

            <section class="content-section" id="informal-introduction">
                <h3 class="section-heading"><strong>Informal Introduction</strong></h3>
            
<p class="paragraph">They provide a way to compare and categorize algorithm efficiencies for large input sizes.</p>
</section>

            <section class="content-section" id="o-notation-big-oh-asymptotic-upper-bound">
                <h3 class="section-heading"><strong>O notation (Big-Oh — Asymptotic Upper Bound)</strong></h3>
            
<p class="paragraph"><strong>Definition (Cormen)</strong>: 
<code>f(n) = O(g(n))</code> if there exist positive constants <code>c</code> and <code>n₀</code> such that <code>0 ≤ f(n) ≤ c*g(n)</code> for all <code>n ≥ n₀</code>.</p>
<p class="paragraph"><strong>Meaning</strong>: <code>f(n)</code> grows <strong>no faster than</strong> <code>g(n)</code> (within a constant factor) for large <code>n</code>.
<strong>Example</strong>: <code>3n² + 100n + 5 = O(n²)</code>.</p>
</section>

            <section class="content-section" id="ω-notation-big-omega-asymptotic-lower-bound">
                <h3 class="section-heading"><strong>Ω-notation (Big-Omega — Asymptotic Lower Bound)</strong></h3>
            
<p class="paragraph"><strong>Definition</strong>: 
<code>f(n) = Ω(g(n))</code> if there exist positive constants <code>c</code> and <code>n₀</code> such that <code>0 ≤ c*g(n) ≤ f(n)</code> for all <code>n ≥ n₀</code>.</p>
<p class="paragraph"><strong>Meaning</strong>: <code>f(n)</code> grows <strong>at least as fast as</strong> <code>g(n)</code> for large <code>n</code>.
<strong>Example</strong>: <code>n³ = Ω(n²)</code>.</p>
</section>

            <section class="content-section" id="θ-notation-big-theta-asymptotic-tight-bound">
                <h3 class="section-heading"><strong>θ-notation (Big-Theta — Asymptotic Tight Bound)</strong></h3>
            
<p class="paragraph"><strong>Definition</strong>:
<code>f(n) = θ(g(n))</code> if there exist positive constants <code>c₁, c₂, and n₀</code> such that <code>0 ≤ c₁<em>g(n) ≤ f(n) ≤ c₂</em>g(n)</code> for all <code>n ≥ n₀</code>.</p>
<p class="paragraph"><strong>Meaning</strong>: <code>f(n)</code> grows <strong>at the same rate as</strong> <code>g(n)</code> for large <code>n</code>. It defines an exact order of growth.
<strong>Example</strong>: <code>½n(n-1) = θ(n²)</code>.</p>
<ul class="content-list"><li><strong>O(g(n))</strong>: <code>f(n)</code> is eventually below some constant multiple of <code>g(n)</code>.</li>
<li><strong>Ω(g(n))</strong>: <code>f(n)</code> is eventually above some constant multiple of <code>g(n)</code>.</li>
<li><strong>θ(g(n))</strong>: <code>f(n)</code> is eventually sandwiched between two constant multiples of <code>g(n)</code>.</li></ul>
<p class="paragraph"><strong>Graphical Interpretation</strong>:</p>
</section>

            <section class="content-section" id="basic-efficiency-classes-levitin">
                <h3 class="section-heading"><strong>Basic Efficiency Classes (Levitin)</strong></h3>
            
<p class="paragraph">| Class        | Name           | Example Algorithms                          |
|--------------|----------------|---------------------------------------------|
| 1            | Constant       | Accessing an array element, assignment      |
| log n        | Logarithmic    | Binary search                               |
| n            | Linear         | Sequential search, finding maximum          |
| n log n      | Linearithmic   | Mergesort, Heapsort, Quicksort (average)    |
| n²           | Quadratic      | Simple sorting (Bubble, Selection, Insertion) |
| n³           | Cubic          | Matrix multiplication (naive)               |
| 2ⁿ           | Exponential    | Traveling Salesman (brute force), Towers of Hanoi |
| n!           | Factorial      | Generating all permutations (brute force)   |</p>
<hr class="content-hr">
</section>

            <section class="content-section" id="10-mathematical-analysis-of-non-recursive-algorithms">
                <h2 class="section-heading"><strong>10. Mathematical Analysis of Non-Recursive Algorithms</strong></h2>
            
</section>

            <section class="content-section" id="general-plan-levitin">
                <h3 class="section-heading"><strong>General Plan (Levitin)</strong>:</h3>
            
<ol class="content-list"><li><strong>Decide on a parameter indicating input size</strong>.</li>
<li><strong>Identify the algorithm's basic operation</strong>.</li>
<li><strong>Check if the number of times the basic operation is executed depends only on input size</strong>. If it also depends on some other property, worst-case, best-case, and average-case analyses may differ.</li>
<li><strong>Set up a sum (series) expressing the count of basic operations</strong>.</li>
<li><strong>Find a closed-form formula for the sum and determine its order of growth</strong>.</li></ol>
</section>

            <section class="content-section" id="example-analysis-selection-sort">
                <h3 class="section-heading"><strong>Example Analysis: Selection Sort</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">Algorithm SelectionSort(A[0..n-1])
for i ← 0 to n-2 do
    min ← i
    for j ← i+1 to n-1 do
        if A[j] &lt; A[min]
            min ← j
    swap A[i] and A[min]</code></pre>
            </div>
            
<ul class="content-list"><li><strong>Input Size</strong>: <code>n</code> = number of elements.</li>
<li><strong>Basic Operation</strong>: Comparison <code>A[j] < A[min]</code>.</li>
<li><strong>Count</strong>: The inner loop runs for <code>j = i+1 to n-1</code>.</li></ul>
<ul class="content-list"><li><strong>Order of Growth</strong>: <code>C(n) = n(n-1)/2 ≈ ½ n²</code> → <strong>θ(n²)</strong>.</li>
<li><strong>Time Complexity</strong>: <strong>θ(n²)</strong> for all cases (worst, best, average) because the comparisons are always performed.</li></ul>
<p class="paragraph">- For <code>i=0</code>, comparisons = <code>n-1</code>.
  - For <code>i=1</code>, comparisons = <code>n-2</code>.
  - ...
  - For <code>i=n-2</code>, comparisons = <code>1</code>.
  - Total comparisons <code>C(n)</code> = <code>(n-1) + (n-2) + ... + 1</code> = <code>n(n-1)/2</code>.</p>
<hr class="content-hr">
</section>

            <section class="content-section" id="11-mathematical-analysis-of-recursive-algorithms">
                <h2 class="section-heading"><strong>11. Mathematical Analysis of Recursive Algorithms</strong></h2>
            
</section>

            <section class="content-section" id="general-plan">
                <h3 class="section-heading"><strong>General Plan</strong>:</h3>
            
<ol class="content-list"><li><strong>Decide on input size parameter</strong>.</li>
<li><strong>Identify the algorithm's basic operation</strong>.</li>
<li><strong>Check if the number of basic operations can vary on different inputs of same size</strong>; if yes, worst/best/average cases need separate analysis.</li>
<li><strong>Set up a recurrence relation</strong> (an equation or inequality) with an initial condition, that expresses the number of times the basic operation is executed for size <code>n</code> in terms of smaller inputs.</li>
<li><strong>Solve the recurrence</strong> to obtain a closed-form expression for the count, or determine its order of growth directly.</li></ol>
</section>

            <section class="content-section" id="methods-to-solve-recurrences-cormen-sridhar">
                <h3 class="section-heading"><strong>Methods to Solve Recurrences</strong> (Cormen, Sridhar):</h3>
            
<ol class="content-list"><li><strong>Substitution Method</strong>: Guess a solution and prove it by induction.</li>
<li><strong>Recursion Tree Method</strong>: Visualize the recurrence as a tree and sum the work at each level.</li>
<li><strong>Master Theorem</strong>: A cookbook solution for recurrences of the form:</li></ol>
<p class="paragraph"><code>T(n) = a T(n/b) + f(n)</code>, where <code>a ≥ 1</code>, <code>b > 1</code>, and <code>f(n)</code> is asymptotically positive.
   The Master Theorem provides solutions based on comparing <code>f(n)</code> with <code>n^(log_b a)</code>.</p>
</section>

            <section class="content-section" id="example-analysis-recursive-factorial">
                <h3 class="section-heading"><strong>Example Analysis: Recursive Factorial</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">Algorithm Factorial(n)
if n = 0
    return 1
else
    return n * Factorial(n-1)</code></pre>
            </div>
            
<ul class="content-list"><li><strong>Input Size</strong>: <code>n</code>.</li>
<li><strong>Basic Operation</strong>: Multiplication.</li>
<li><strong>Recurrence Relation</strong>: <code>M(n) = M(n-1) + 1</code> for <code>n > 0</code>, with initial condition <code>M(0) = 0</code>.</li>
<li><strong>Solution</strong>: <code>M(n) = M(n-1) + 1 = [M(n-2)+1] + 1 = ... = M(0) + n = n</code>.</li>
<li><strong>Time Complexity</strong>: <strong>θ(n)</strong>.</li></ul>
</section>

            <section class="content-section" id="example-analysis-recursive-binary-search">
                <h3 class="section-heading"><strong>Example Analysis: Recursive Binary Search</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">Algorithm BinarySearch(A[0..n-1], K, l, r) // l=left, r=right index
if l &gt; r return -1
m ← ⌊(l+r)/2⌋
if K == A[m] return m
else if K &lt; A[m]
    return BinarySearch(A, K, l, m-1)
else
    return BinarySearch(A, K, m+1, r)</code></pre>
            </div>
            
<ul class="content-list"><li><strong>Input Size</strong>: Number of elements in the subarray, <code>n = r-l+1</code>.</li>
<li><strong>Basic Operation</strong>: Comparison <code>K == A[m]</code>.</li>
<li><strong>Worst-case Recurrence</strong>: In the worst case, key not found, size reduces by half each time.</li></ul>
<ul class="content-list"><li><strong>Solution (using Master Theorem or iteration)</strong>:</li></ul>
<ul class="content-list"><li><strong>Time Complexity</strong>: <strong>θ(log n)</strong>.</li></ul>
<p class="paragraph"><code>T(n) = T(n/2) + 1</code> for <code>n > 1</code>, with <code>T(1) = 1</code>.
  - Assume <code>n = 2^k</code>.
  - <code>T(2^k) = T(2^(k-1)) + 1 = [T(2^(k-2)) + 1] + 1 = ... = T(1) + k = 1 + k</code>.
  - Since <code>k = log₂ n</code>, <code>T(n) = log₂ n + 1</code>.</p>
</section>

            <section class="content-section" id="unit-2-brute-force-and-exhaustive-search">
                <h1 class="section-heading"><strong>Unit 2: Brute Force and Exhaustive Search</strong></h1>
            
</section>

            <section class="content-section" id="1-introduction-to-brute-force-approach">
                <h2 class="section-heading"><strong>1. Introduction to Brute Force Approach</strong></h2>
            
</section>

            <section class="content-section" id="meaning-concept">
                <h3 class="section-heading"><strong>Meaning / Concept</strong></h3>
            
<p class="paragraph"><strong>Brute Force</strong> is a straightforward, direct approach to problem-solving that relies on sheer computing power rather than sophisticated techniques. It systematically enumerates all possible candidates for the solution and checks whether each candidate satisfies the problem's statement.</p>
<p class="paragraph"><strong>Key Idea</strong>: "Try them all" or "Generate and Test" - It explores every possibility until a solution is found or all possibilities are exhausted.</p>
</section>

            <section class="content-section" id="formal-definition">
                <h3 class="section-heading"><strong>Formal Definition</strong></h3>
            
<p class="paragraph">According to <strong>Levitin</strong>, brute force is a straightforward approach to solving a problem directly, based on the problem statement and definitions of the concepts involved. <strong>Horowitz & Sahni</strong> describe it as the most simple and straightforward method that directly applies the problem statement without any optimizations.</p>
</section>

            <section class="content-section" id="need-purpose-applications">
                <h3 class="section-heading"><strong>Need / Purpose / Applications</strong></h3>
            
<ul class="content-list"><li><strong>Purpose</strong>: To solve problems by direct implementation of the problem statement when no other efficient algorithm is known or required.</li>
<li><strong>Need</strong>: Serves as a baseline for comparing more sophisticated algorithms. Always yields a correct solution if one exists.</li>
<li><strong>Applications</strong>: Simple search and sorting problems, pattern matching, combinatorial problems, and as a fallback when problem size is small.</li></ul>
</section>

            <section class="content-section" id="characteristics-properties">
                <h3 class="section-heading"><strong>Characteristics / Properties</strong></h3>
            
<ol class="content-list"><li><strong>Simplicity</strong>: Easy to understand and implement.</li>
<li><strong>Generality</strong>: Applicable to a wide variety of problems.</li>
<li><strong>Guaranteed Correctness</strong>: If implemented correctly, it always finds a solution if one exists.</li>
<li><strong>Inefficiency</strong>: Often has prohibitively high time complexity for large inputs.</li>
<li><strong>No Optimization</strong>: Doesn't use problem-specific insights to reduce computation.</li></ol>
</section>

            <section class="content-section" id="advantages">
                <h3 class="section-heading"><strong>Advantages</strong></h3>
            
<ol class="content-list"><li><strong>Simple to design and implement</strong>.</li>
<li><strong>Always yields a solution</strong> (if one exists).</li>
<li><strong>Useful for solving small instances</strong> of problems.</li>
<li><strong>Provides a benchmark</strong> for evaluating more efficient algorithms.</li>
<li><strong>No special knowledge of the problem domain required</strong>.</li></ol>
</section>

            <section class="content-section" id="limitations">
                <h3 class="section-heading"><strong>Limitations</strong></h3>
            
<ol class="content-list"><li><strong>Inefficient for large problem sizes</strong>.</li>
<li><strong>Wasteful of computational resources</strong>.</li>
<li><strong>Impractical for real-time applications</strong> with large inputs.</li>
<li><strong>Does not scale well</strong> with increasing input size.</li></ol>
<hr class="content-hr">
</section>

            <section class="content-section" id="2-selection-sort">
                <h2 class="section-heading"><strong>2. Selection Sort</strong></h2>
            
</section>

            <section class="content-section" id="meaning-concept">
                <h3 class="section-heading"><strong>Meaning / Concept</strong></h3>
            
<p class="paragraph">Selection Sort is a simple comparison-based sorting algorithm that works by repeatedly finding the minimum element from the unsorted part and putting it at the beginning.</p>
</section>

            <section class="content-section" id="algorithm-step-by-step">
                <h3 class="section-heading"><strong>Algorithm (Step-by-Step)</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">Algorithm SelectionSort(A[0..n-1])
// Sorts a given array by selection sort
// Input: An array A[0..n-1] of orderable elements
// Output: Array A[0..n-1] sorted in non-decreasing order
for i ← 0 to n-2 do
    min ← i
    for j ← i+1 to n-1 do
        if A[j] &lt; A[min]
            min ← j
    // Swap A[i] and A[min]
    temp ← A[i]
    A[i] ← A[min]
    A[min] ← temp</code></pre>
            </div>
            
</section>

            <section class="content-section" id="explanation-of-the-algorithm">
                <h3 class="section-heading"><strong>Explanation of the Algorithm</strong></h3>
            
<ol class="content-list"><li>The outer loop runs from <code>i = 0</code> to <code>n-2</code>. After <code>i</code> iterations, the first <code>i</code> elements are sorted.</li>
<li>For each <code>i</code>, the inner loop finds the smallest element in the subarray <code>A[i..n-1]</code>.</li>
<li>The index of this smallest element is stored in <code>min</code>.</li>
<li>Swap the element at position <code>i</code> with the element at position <code>min</code>.</li></ol>
</section>

            <section class="content-section" id="example-problem-with-working-steps">
                <h3 class="section-heading"><strong>Example Problem with Working Steps</strong></h3>
            
<p class="paragraph"><strong>Problem</strong>: Sort [64, 25, 12, 22, 11] using Selection Sort.</p>
<ul class="content-list"><li>Find min in [64, 25, 12, 22, 11] → min index = 4 (value 11)</li>
<li>Swap A[0] and A[4] → [11, 25, 12, 22, 64]</li></ul>
<p class="paragraph"><strong>Pass 1 (i=0)</strong>:</p>
<ul class="content-list"><li>Find min in [25, 12, 22, 64] → min index = 2 (value 12)</li>
<li>Swap A[1] and A[2] → [11, 12, 25, 22, 64]</li></ul>
<p class="paragraph"><strong>Pass 2 (i=1)</strong>:</p>
<ul class="content-list"><li>Find min in [25, 22, 64] → min index = 3 (value 22)</li>
<li>Swap A[2] and A[3] → [11, 12, 22, 25, 64]</li></ul>
<p class="paragraph"><strong>Pass 3 (i=2)</strong>:</p>
<ul class="content-list"><li>Find min in [25, 64] → min index = 3 (value 25) [no swap needed]</li>
<li>Array is now sorted: [11, 12, 22, 25, 64]</li></ul>
<p class="paragraph"><strong>Pass 4 (i=3)</strong>:</p>
</section>

            <section class="content-section" id="time-complexity">
                <h3 class="section-heading"><strong>Time Complexity</strong></h3>
            
<ul class="content-list"><li><strong>Best Case</strong>: O(n²) - Even if array is sorted, still compares all elements</li>
<li><strong>Average Case</strong>: Θ(n²)</li>
<li><strong>Worst Case</strong>: O(n²)</li></ul>
<p class="paragraph"><strong>Justification</strong>: Number of comparisons = <code>(n-1) + (n-2) + ... + 1 = n(n-1)/2 ≈ ½n²</code></p>
</section>

            <section class="content-section" id="space-complexity">
                <h3 class="section-heading"><strong>Space Complexity</strong></h3>
            
<p class="paragraph">O(1) - <strong>Constant space</strong>, only uses a few temporary variables.</p>
</section>

            <section class="content-section" id="functions-operations-involved">
                <h3 class="section-heading"><strong>Functions / Operations Involved</strong></h3>
            
<ol class="content-list"><li><strong>Comparison</strong>: <code>A[j] < A[min]</code></li>
<li><strong>Assignment</strong>: <code>min = j</code>, <code>temp = A[i]</code></li>
<li><strong>Swapping</strong>: Exchange two elements</li></ol>
</section>

            <section class="content-section" id="characteristics">
                <h3 class="section-heading"><strong>Characteristics</strong></h3>
            
<ol class="content-list"><li><strong>In-place sorting</strong> (requires only O(1) extra memory)</li>
<li><strong>Not stable</strong> (may change relative order of equal elements)</li>
<li><strong>Number of swaps</strong>: O(n) - makes at most n-1 swaps</li>
<li><strong>Adaptive</strong>: No - always performs same comparisons regardless of input</li></ol>
</section>

            <section class="content-section" id="real-world-usage-examples">
                <h3 class="section-heading"><strong>Real-world Usage Examples</strong></h3>
            
<ul class="content-list"><li>Sorting small arrays in embedded systems</li>
<li>Educational purposes to teach sorting concepts</li>
<li>When memory is extremely limited</li></ul>
<hr class="content-hr">
</section>

            <section class="content-section" id="3-bubble-sort">
                <h2 class="section-heading"><strong>3. Bubble Sort</strong></h2>
            
</section>

            <section class="content-section" id="meaning-concept">
                <h3 class="section-heading"><strong>Meaning / Concept</strong></h3>
            
<p class="paragraph">Bubble Sort is a simple comparison-based sorting algorithm that repeatedly steps through the list, compares adjacent elements, and swaps them if they are in the wrong order. The pass through the list is repeated until no swaps are needed.</p>
</section>

            <section class="content-section" id="algorithm-step-by-step">
                <h3 class="section-heading"><strong>Algorithm (Step-by-Step)</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">Algorithm BubbleSort(A[0..n-1])
// Sorts a given array by bubble sort
// Input: An array A[0..n-1] of orderable elements
// Output: Array A[0..n-1] sorted in non-decreasing order
for i ← 0 to n-2 do
    for j ← 0 to n-2-i do
        if A[j+1] &lt; A[j]
            // Swap A[j] and A[j+1]
            temp ← A[j]
            A[j] ← A[j+1]
            A[j+1] ← temp</code></pre>
            </div>
            
</section>

            <section class="content-section" id="optimized-version-with-early-termination">
                <h3 class="section-heading"><strong>Optimized Version (with early termination)</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">Algorithm BubbleSortOptimized(A[0..n-1])
swapped ← true
i ← 0
while swapped do
    swapped ← false
    for j ← 0 to n-2-i do
        if A[j+1] &lt; A[j]
            swap A[j] and A[j+1]
            swapped ← true
    i ← i + 1</code></pre>
            </div>
            
</section>

            <section class="content-section" id="explanation-of-the-algorithm">
                <h3 class="section-heading"><strong>Explanation of the Algorithm</strong></h3>
            
<ol class="content-list"><li>In each pass (outer loop), the largest unsorted element "bubbles up" to its correct position at the end.</li>
<li>The inner loop compares adjacent pairs and swaps them if they're in wrong order.</li>
<li>After each pass, the next largest element is in place, so inner loop range decreases.</li>
<li>The optimized version stops early if no swaps occur (array is sorted).</li></ol>
</section>

            <section class="content-section" id="example-problem-with-working-steps">
                <h3 class="section-heading"><strong>Example Problem with Working Steps</strong></h3>
            
<p class="paragraph"><strong>Problem</strong>: Sort [5, 1, 4, 2, 8] using Bubble Sort.</p>
<ul class="content-list"><li>(5,1) → swap → [1, 5, 4, 2, 8]</li>
<li>(5,4) → swap → [1, 4, 5, 2, 8]</li>
<li>(5,2) → swap → [1, 4, 2, 5, 8]</li>
<li>(5,8) → no swap → [1, 4, 2, 5, 8]</li></ul>
<p class="paragraph"><strong>First Pass</strong>:
<em>8 is now in correct position</em></p>
<ul class="content-list"><li>(1,4) → no swap → [1, 4, 2, 5, 8]</li>
<li>(4,2) → swap → [1, 2, 4, 5, 8]</li>
<li>(4,5) → no swap → [1, 2, 4, 5, 8]</li></ul>
<p class="paragraph"><strong>Second Pass</strong>:
<em>5 is now in correct position</em></p>
<ul class="content-list"><li>(1,2) → no swap → [1, 2, 4, 5, 8]</li>
<li>(2,4) → no swap → [1, 2, 4, 5, 8]</li></ul>
<p class="paragraph"><strong>Third Pass</strong>:
<em>Array is sorted, algorithm can stop</em></p>
</section>

            <section class="content-section" id="time-complexity">
                <h3 class="section-heading"><strong>Time Complexity</strong></h3>
            
<ul class="content-list"><li><strong>Best Case (Optimized)</strong>: O(n) - Array already sorted, one pass with n-1 comparisons</li>
<li><strong>Average Case</strong>: Θ(n²)</li>
<li><strong>Worst Case</strong>: O(n²) - Array sorted in reverse order</li></ul>
</section>

            <section class="content-section" id="space-complexity">
                <h3 class="section-heading"><strong>Space Complexity</strong></h3>
            
<p class="paragraph">O(1) - <strong>Constant space</strong>, in-place sorting.</p>
</section>

            <section class="content-section" id="functions-operations-involved">
                <h3 class="section-heading"><strong>Functions / Operations Involved</strong></h3>
            
<ol class="content-list"><li><strong>Comparison</strong>: <code>A[j+1] < A[j]</code></li>
<li><strong>Swapping</strong>: Exchange adjacent elements</li>
<li><strong>Flag checking</strong>: In optimized version</li></ol>
</section>

            <section class="content-section" id="characteristics">
                <h3 class="section-heading"><strong>Characteristics</strong></h3>
            
<ol class="content-list"><li><strong>In-place sorting</strong></li>
<li><strong>Stable sort</strong> (preserves relative order of equal elements)</li>
<li><strong>Adaptive</strong> (optimized version can detect sorted array early)</li>
<li><strong>Number of swaps</strong>: Can be O(n²) in worst case</li></ol>
</section>

            <section class="content-section" id="real-world-usage-examples">
                <h3 class="section-heading"><strong>Real-world Usage Examples</strong></h3>
            
<ul class="content-list"><li>Sorting small datasets</li>
<li>Educational purposes</li>
<li>When simplicity is more important than efficiency</li></ul>
<hr class="content-hr">
</section>

            <section class="content-section" id="4-sequential-search">
                <h2 class="section-heading"><strong>4. Sequential Search</strong></h2>
            
</section>

            <section class="content-section" id="meaning-concept">
                <h3 class="section-heading"><strong>Meaning / Concept</strong></h3>
            
<p class="paragraph">Also known as Linear Search, it scans each element of a list sequentially until the target element is found or the list ends.</p>
</section>

            <section class="content-section" id="algorithm-step-by-step">
                <h3 class="section-heading"><strong>Algorithm (Step-by-Step)</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">Algorithm SequentialSearch(A[0..n-1], K)
// Searches for a given value in a given array
// Input: An array A[0..n-1] and a search key K
// Output: Index of the first element equal to K, or -1 if not found
i ← 0
while i &lt; n and A[i] ≠ K do
    i ← i + 1
if i &lt; n return i
else return -1</code></pre>
            </div>
            
</section>

            <section class="content-section" id="enhanced-version-with-sentinel">
                <h3 class="section-heading"><strong>Enhanced Version (with Sentinel)</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">Algorithm SequentialSearchWithSentinel(A[0..n], K)
// Uses A[n] as sentinel
A[n] ← K  // Add sentinel
i ← 0
while A[i] ≠ K do
    i ← i + 1
if i &lt; n return i
else return -1</code></pre>
            </div>
            
</section>

            <section class="content-section" id="explanation-of-the-algorithm">
                <h3 class="section-heading"><strong>Explanation of the Algorithm</strong></h3>
            
<ol class="content-list"><li>Start from the first element.</li>
<li>Compare each element with the search key <code>K</code>.</li>
<li>If found, return the index.</li>
<li>If end of array is reached without finding, return -1.</li>
<li>Sentinel version eliminates the boundary check in the loop.</li></ol>
</section>

            <section class="content-section" id="example-problem-with-working-steps">
                <h3 class="section-heading"><strong>Example Problem with Working Steps</strong></h3>
            
<p class="paragraph"><strong>Problem</strong>: Search for key = 22 in array [11, 25, 12, 22, 64]</p>
<ol class="content-list"><li>i=0: A[0]=11 ≠ 22 → continue</li>
<li>i=1: A[1]=25 ≠ 22 → continue</li>
<li>i=2: A[2]=12 ≠ 22 → continue</li>
<li>i=3: A[3]=22 = 22 → found!</li>
<li>Return index 3</li></ol>
<p class="paragraph"><strong>Steps</strong>:</p>
</section>

            <section class="content-section" id="time-complexity">
                <h3 class="section-heading"><strong>Time Complexity</strong></h3>
            
<ul class="content-list"><li><strong>Best Case</strong>: O(1) - Key found at first position</li>
<li><strong>Average Case</strong>: Θ(n) - Key found roughly in the middle</li>
<li><strong>Worst Case</strong>: O(n) - Key not present or at last position</li></ul>
</section>

            <section class="content-section" id="space-complexity">
                <h3 class="section-heading"><strong>Space Complexity</strong></h3>
            
<p class="paragraph">O(1) - Constant space.</p>
</section>

            <section class="content-section" id="functions-operations-involved">
                <h3 class="section-heading"><strong>Functions / Operations Involved</strong></h3>
            
<ol class="content-list"><li><strong>Comparison</strong>: <code>A[i] ≠ K</code></li>
<li><strong>Increment</strong>: <code>i ← i + 1</code></li>
<li><strong>Assignment</strong>: For sentinel version</li></ol>
</section>

            <section class="content-section" id="characteristics">
                <h3 class="section-heading"><strong>Characteristics</strong></h3>
            
<ol class="content-list"><li><strong>Simple and straightforward</strong></li>
<li><strong>Works on both sorted and unsorted arrays</strong></li>
<li><strong>No preprocessing required</strong></li>
<li><strong>Inefficient for large datasets</strong></li></ol>
</section>

            <section class="content-section" id="real-world-usage-examples">
                <h3 class="section-heading"><strong>Real-world Usage Examples</strong></h3>
            
<ul class="content-list"><li>Searching small lists</li>
<li>When data is unsorted</li>
<li>Simple database queries on small tables</li></ul>
<hr class="content-hr">
</section>

            <section class="content-section" id="5-exhaustive-search">
                <h2 class="section-heading"><strong>5. Exhaustive Search</strong></h2>
            
</section>

            <section class="content-section" id="meaning-concept">
                <h3 class="section-heading"><strong>Meaning / Concept</strong></h3>
            
<p class="paragraph">Exhaustive Search is a brute force technique that systematically enumerates all possible solutions to a combinatorial problem and checks each one to see if it satisfies the problem constraints.</p>
</section>

            <section class="content-section" id="formal-definition">
                <h3 class="section-heading"><strong>Formal Definition</strong></h3>
            
<p class="paragraph"><strong>Levitin</strong> defines exhaustive search as a brute force approach to combinatorial problems that generates each element of the problem's domain and checks whether it satisfies the problem's constraints.</p>
</section>

            <section class="content-section" id="key-idea">
                <h3 class="section-heading"><strong>Key Idea</strong></h3>
            
<p class="paragraph">"Generate all possible candidates and test each one."</p>
</section>

            <section class="content-section" id="applications">
                <h3 class="section-heading"><strong>Applications</strong></h3>
            
<ol class="content-list"><li><strong>Traveling Salesman Problem</strong> (TSP)</li>
<li><strong>Knapsack Problem</strong></li>
<li><strong>Assignment Problem</strong></li>
<li><strong>Subset Sum Problem</strong></li>
<li><strong>Permutation Problems</strong></li></ol>
</section>

            <section class="content-section" id="characteristics">
                <h3 class="section-heading"><strong>Characteristics</strong></h3>
            
<ol class="content-list"><li><strong>Guarantees optimal solution</strong> (if one exists)</li>
<li><strong>Extremely time-consuming</strong> for large n</li>
<li><strong>Simple to implement</strong></li>
<li><strong>Useful only for small problem instances</strong></li></ol>
</section>

            <section class="content-section" id="when-to-use">
                <h3 class="section-heading"><strong>When to Use</strong></h3>
            
<ul class="content-list"><li>Problem size is small (n ≤ 20)</li>
<li>When optimal solution is absolutely required</li>
<li>As a baseline for testing heuristic algorithms</li></ul>
<hr class="content-hr">
</section>

            <section class="content-section" id="6-traveling-salesman-problem-tsp">
                <h2 class="section-heading"><strong>6. Traveling Salesman Problem (TSP)</strong></h2>
            
</section>

            <section class="content-section" id="meaning-concept">
                <h3 class="section-heading"><strong>Meaning / Concept</strong></h3>
            
<p class="paragraph">Given n cities and distances between each pair, find the shortest possible route that visits each city exactly once and returns to the origin city.</p>
</section>

            <section class="content-section" id="formal-definition">
                <h3 class="section-heading"><strong>Formal Definition</strong></h3>
            
<p class="paragraph">A Hamiltonian cycle of minimum weight in a complete weighted graph.</p>
</section>

            <section class="content-section" id="brute-force-approach">
                <h3 class="section-heading"><strong>Brute Force Approach</strong></h3>
            
<p class="paragraph">Generate all (n-1)! permutations of cities (excluding the starting city), calculate the total distance for each permutation, and select the shortest.</p>
</section>

            <section class="content-section" id="algorithm-step-by-step">
                <h3 class="section-heading"><strong>Algorithm (Step-by-Step)</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">Algorithm TSP_BruteForce(dist[1..n][1..n])
// Computes shortest tour using brute force
// Input: Distance matrix dist where dist[i][j] is distance from i to j
// Output: Minimum tour length
minDistance ← ∞
Generate all permutations of cities {2, 3, ..., n}
for each permutation P do
    currentDistance ← dist[1][P[1]]
    for i ← 1 to n-2 do
        currentDistance ← currentDistance + dist[P[i]][P[i+1]]
    currentDistance ← currentDistance + dist[P[n-1]][1]
    
    if currentDistance &lt; minDistance then
        minDistance ← currentDistance
        bestTour ← P
return minDistance</code></pre>
            </div>
            
</section>

            <section class="content-section" id="example-problem-with-working-steps">
                <h3 class="section-heading"><strong>Example Problem with Working Steps</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">    A   B   C   D
A   0   10  15  20
B   10  0   35  25
C   15  35  0   30
D   20  25  30  0</code></pre>
            </div>
            
<p class="paragraph"><strong>Problem</strong>: 4 cities with distances:
Starting city = A</p>
<ol class="content-list"><li>A→B→C→D→A: 10 + 35 + 30 + 20 = 95</li>
<li>A→B→D→C→A: 10 + 25 + 30 + 15 = 80</li>
<li>A→C→B→D→A: 15 + 35 + 25 + 20 = 95</li>
<li>A→C→D→B→A: 15 + 30 + 25 + 10 = 80</li>
<li>A→D→B→C→A: 20 + 25 + 35 + 15 = 95</li>
<li>A→D→C→B→A: 20 + 30 + 35 + 10 = 95</li></ol>
<p class="paragraph"><strong>All possible tours (starting and ending at A)</strong>:</p>
<p class="paragraph"><strong>Optimal tours</strong>: A→B→D→C→A or A→C→D→B→A with distance 80.</p>
</section>

            <section class="content-section" id="time-complexity">
                <h3 class="section-heading"><strong>Time Complexity</strong></h3>
            
<p class="paragraph">O((n-1)!) - Must examine all permutations of n-1 cities.</p>
</section>

            <section class="content-section" id="space-complexity">
                <h3 class="section-heading"><strong>Space Complexity</strong></h3>
            
<p class="paragraph">O(n) - To store current permutation.</p>
</section>

            <section class="content-section" id="limitations">
                <h3 class="section-heading"><strong>Limitations</strong></h3>
            
<ul class="content-list"><li><strong>Factorial complexity</strong>: For n=20, (n-1)! ≈ 1.2×10¹⁷ permutations</li>
<li><strong>Impractical</strong> for n > 15 on typical computers</li></ul>
</section>

            <section class="content-section" id="real-world-usage-examples">
                <h3 class="section-heading"><strong>Real-world Usage Examples</strong></h3>
            
<ul class="content-list"><li>Logistics and delivery route planning (for small number of stops)</li>
<li>Circuit board drilling</li>
<li>DNA sequencing</li></ul>
<hr class="content-hr">
</section>

            <section class="content-section" id="7-knapsack-problem">
                <h2 class="section-heading"><strong>7. Knapsack Problem</strong></h2>
            
</section>

            <section class="content-section" id="meaning-concept">
                <h3 class="section-heading"><strong>Meaning / Concept</strong></h3>
            
<p class="paragraph">Given n items with weights wᵢ and values vᵢ, and a knapsack of capacity W, find the most valuable subset of items that fits in the knapsack.</p>
</section>

            <section class="content-section" id="formal-definition">
                <h3 class="section-heading"><strong>Formal Definition</strong></h3>
            
<ol class="content-list"><li><strong>0/1 Knapsack</strong>: Each item either taken completely or not taken.</li>
<li><strong>Fractional Knapsack</strong>: Items can be taken fractionally (solved by greedy approach).</li></ol>
<p class="paragraph">Two versions:</p>
</section>

            <section class="content-section" id="brute-force-approach-for-01-knapsack">
                <h3 class="section-heading"><strong>Brute Force Approach for 0/1 Knapsack</strong></h3>
            
<p class="paragraph">Generate all 2ⁿ subsets of items, check weight constraint for each, and select the subset with maximum total value within weight limit.</p>
</section>

            <section class="content-section" id="algorithm-step-by-step">
                <h3 class="section-heading"><strong>Algorithm (Step-by-Step)</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">Algorithm Knapsack_BruteForce(w[1..n], v[1..n], W)
// Solves 0/1 knapsack by exhaustive search
// Input: Arrays w (weights), v (values), capacity W
// Output: Maximum achievable value
maxValue ← 0
for each subset S of {1, 2, ..., n} do
    totalWeight ← 0
    totalValue ← 0
    for each i in S do
        totalWeight ← totalWeight + w[i]
        totalValue ← totalValue + v[i]
    if totalWeight ≤ W and totalValue &gt; maxValue then
        maxValue ← totalValue
        bestSubset ← S
return maxValue</code></pre>
            </div>
            
</section>

            <section class="content-section" id="example-problem-with-working-steps">
                <h3 class="section-heading"><strong>Example Problem with Working Steps</strong></h3>
            
<ul class="content-list"><li>Item 1: w=7, v=$42</li>
<li>Item 2: w=3, v=$12</li>
<li>Item 3: w=4, v=$40</li>
<li>Item 4: w=5, v=$25</li></ul>
<p class="paragraph"><strong>Problem</strong>: W=10, items:</p>
<ul class="content-list"><li>{}: value=0, weight=0</li>
<li>{1}: value=42, weight=7 ✓</li>
<li>{2}: value=12, weight=3 ✓</li>
<li>{3}: value=40, weight=4 ✓</li>
<li>{4}: value=25, weight=5 ✓</li>
<li>{1,2}: value=54, weight=10 ✓ (current best)</li>
<li>{1,3}: value=82, weight=11 ✗ (exceeds capacity)</li>
<li>{1,4}: value=67, weight=12 ✗</li>
<li>{2,3}: value=52, weight=7 ✓</li>
<li>{2,4}: value=37, weight=8 ✓</li>
<li>{3,4}: value=65, weight=9 ✓</li>
<li>{1,2,3}: value=94, weight=14 ✗</li>
<li>{1,2,4}: value=79, weight=15 ✗</li>
<li>{1,3,4}: value=107, weight=16 ✗</li>
<li>{2,3,4}: value=77, weight=12 ✗</li>
<li>{1,2,3,4}: value=119, weight=19 ✗</li></ul>
<p class="paragraph"><strong>All subsets</strong>:</p>
<p class="paragraph"><strong>Optimal solution</strong>: {1,2} with value $54, weight 10.</p>
</section>

            <section class="content-section" id="time-complexity">
                <h3 class="section-heading"><strong>Time Complexity</strong></h3>
            
<p class="paragraph">O(2ⁿ × n) - 2ⁿ subsets, each requiring O(n) to compute weight and value.</p>
</section>

            <section class="content-section" id="space-complexity">
                <h3 class="section-heading"><strong>Space Complexity</strong></h3>
            
<p class="paragraph">O(n) - To store current subset.</p>
</section>

            <section class="content-section" id="characteristics">
                <h3 class="section-heading"><strong>Characteristics</strong></h3>
            
<ol class="content-list"><li><strong>Guarantees optimal solution</strong></li>
<li><strong>Impractical for n > 30</strong></li>
<li><strong>NP-Complete problem</strong> - No known polynomial time algorithm</li></ol>
</section>

            <section class="content-section" id="real-world-usage-examples">
                <h3 class="section-heading"><strong>Real-world Usage Examples</strong></h3>
            
<ul class="content-list"><li>Resource allocation</li>
<li>Investment portfolio selection</li>
<li>Cutting stock problems</li></ul>
<hr class="content-hr">
</section>

            <section class="content-section" id="8-depth-first-search-dfs">
                <h2 class="section-heading"><strong>8. Depth First Search (DFS)</strong></h2>
            
</section>

            <section class="content-section" id="meaning-concept">
                <h3 class="section-heading"><strong>Meaning / Concept</strong></h3>
            
<p class="paragraph">DFS is a graph traversal algorithm that explores as far as possible along each branch before backtracking. It uses a stack (either explicitly or via recursion) to keep track of vertices.</p>
</section>

            <section class="content-section" id="algorithm-step-by-step">
                <h3 class="section-heading"><strong>Algorithm (Step-by-Step)</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">Algorithm DFS(G)
// Performs DFS traversal of graph G
// Input: Graph G = (V, E)
// Output: DFS numbering of vertices
for each vertex v in V do
    visited[v] ← false
time ← 0
for each vertex v in V do
    if not visited[v]
        DFS_Visit(v)

Procedure DFS_Visit(v)
visited[v] ← true
previsit(v)  // Record discovery time
for each vertex w adjacent to v do
    if not visited[w]
        DFS_Visit(w)
postvisit(v)  // Record finishing time</code></pre>
            </div>
            
<p class="paragraph"><strong>Recursive Version</strong>:</p>

            <div class="code-block">
                <pre><code class="language-text">Algorithm DFS_Iterative(G, s)
// Non-recursive DFS starting from vertex s
stack ← empty stack
stack.push(s)
while stack is not empty do
    v ← stack.pop()
    if not visited[v]
        visited[v] ← true
        process(v)
        for each neighbor w of v (in reverse order for same order as recursive) do
            if not visited[w]
                stack.push(w)</code></pre>
            </div>
            
<p class="paragraph"><strong>Iterative Version</strong>:</p>
</section>

            <section class="content-section" id="explanation-of-the-algorithm">
                <h3 class="section-heading"><strong>Explanation of the Algorithm</strong></h3>
            
<ol class="content-list"><li>Start from a source vertex.</li>
<li>Mark it as visited.</li>
<li>Recursively visit all unvisited neighbors.</li>
<li>When a vertex has no unvisited neighbors, backtrack.</li>
<li>Continue until all vertices are visited.</li></ol>
</section>

            <section class="content-section" id="example-problem-with-working-steps">
                <h3 class="section-heading"><strong>Example Problem with Working Steps</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">    A
   / \
  B   C
  |   |
  D---E</code></pre>
            </div>
            
<p class="paragraph"><strong>Problem</strong>: Traverse this graph starting from A:</p>
<ol class="content-list"><li>Visit A</li>
<li>From A, go to B (choose alphabetically)</li>
<li>From B, go to D</li>
<li>From D, go to E</li>
<li>From E, go to C</li>
<li>Backtrack as all vertices visited</li></ol>
<p class="paragraph"><strong>DFS traversal starting from A</strong>:</p>
<p class="paragraph"><strong>Order</strong>: A → B → D → E → C</p>
</section>

            <section class="content-section" id="time-complexity">
                <h3 class="section-heading"><strong>Time Complexity</strong></h3>
            
<ul class="content-list"><li><strong>Adjacency Matrix</strong>: O(V²)</li>
<li><strong>Adjacency List</strong>: O(V + E)</li></ul>
<p class="paragraph">where V = vertices, E = edges</p>
</section>

            <section class="content-section" id="space-complexity">
                <h3 class="section-heading"><strong>Space Complexity</strong></h3>
            
<ul class="content-list"><li><strong>Recursive</strong>: O(V) for recursion stack</li>
<li><strong>Iterative</strong>: O(V) for explicit stack</li></ul>
</section>

            <section class="content-section" id="applications">
                <h3 class="section-heading"><strong>Applications</strong></h3>
            
<ol class="content-list"><li><strong>Cycle detection</strong> in graphs</li>
<li><strong>Topological sorting</strong> of DAGs</li>
<li><strong>Solving puzzles</strong> (mazes, Sudoku)</li>
<li><strong>Finding connected components</strong></li>
<li><strong>Path finding</strong></li></ol>
</section>

            <section class="content-section" id="characteristics">
                <h3 class="section-heading"><strong>Characteristics</strong></h3>
            
<ol class="content-list"><li><strong>Uses LIFO structure</strong> (stack)</li>
<li><strong>May not find shortest path</strong></li>
<li><strong>Memory efficient</strong> for deep graphs</li>
<li><strong>Can get stuck in infinite loops</strong> if cycles not handled</li></ol>
<hr class="content-hr">
</section>

            <section class="content-section" id="9-breadth-first-search-bfs">
                <h2 class="section-heading"><strong>9. Breadth First Search (BFS)</strong></h2>
            
</section>

            <section class="content-section" id="meaning-concept">
                <h3 class="section-heading"><strong>Meaning / Concept</strong></h3>
            
<p class="paragraph">BFS is a graph traversal algorithm that explores all neighbors at the present depth before moving to nodes at the next depth level. It uses a queue to keep track of vertices.</p>
</section>

            <section class="content-section" id="algorithm-step-by-step">
                <h3 class="section-heading"><strong>Algorithm (Step-by-Step)</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">Algorithm BFS(G, s)
// Performs BFS traversal of graph G starting from vertex s
// Input: Graph G = (V, E), starting vertex s
// Output: BFS ordering and distances from s
for each vertex v in V do
    visited[v] ← false
    distance[v] ← ∞
    parent[v] ← nil

queue ← empty queue
visited[s] ← true
distance[s] ← 0
queue.enqueue(s)

while queue is not empty do
    v ← queue.dequeue()
    process(v)
    for each vertex w adjacent to v do
        if not visited[w]
            visited[w] ← true
            distance[w] ← distance[v] + 1
            parent[w] ← v
            queue.enqueue(w)</code></pre>
            </div>
            
</section>

            <section class="content-section" id="explanation-of-the-algorithm">
                <h3 class="section-heading"><strong>Explanation of the Algorithm</strong></h3>
            
<ol class="content-list"><li>Start from source vertex, mark as visited, distance = 0.</li>
<li>Add to queue.</li>
<li>While queue not empty:</li></ol>
<p class="paragraph">- Dequeue a vertex.
   - Process it.
   - Enqueue all unvisited neighbors.
   - Mark neighbors as visited and update distances.</p>
</section>

            <section class="content-section" id="example-problem-with-working-steps">
                <h3 class="section-heading"><strong>Example Problem with Working Steps</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">    A
   / \
  B   C
  |   |
  D---E</code></pre>
            </div>
            
<p class="paragraph"><strong>Problem</strong>: Traverse same graph starting from A:</p>
<ol class="content-list"><li>Level 0: A</li>
<li>Level 1: B, C (neighbors of A)</li>
<li>Level 2: D (from B), E (from C)</li></ol>
<p class="paragraph"><strong>BFS traversal starting from A</strong>:</p>
<p class="paragraph"><strong>Order</strong>: A → B → C → D → E</p>
</section>

            <section class="content-section" id="time-complexity">
                <h3 class="section-heading"><strong>Time Complexity</strong></h3>
            
<ul class="content-list"><li><strong>Adjacency Matrix</strong>: O(V²)</li>
<li><strong>Adjacency List</strong>: O(V + E)</li></ul>
</section>

            <section class="content-section" id="space-complexity">
                <h3 class="section-heading"><strong>Space Complexity</strong></h3>
            
<p class="paragraph">O(V) - For queue and visited array.</p>
</section>

            <section class="content-section" id="applications">
                <h3 class="section-heading"><strong>Applications</strong></h3>
            
<ol class="content-list"><li><strong>Shortest path</strong> in unweighted graphs</li>
<li><strong>Social network analysis</strong> (degrees of separation)</li>
<li><strong>Web crawling</strong></li>
<li><strong>Broadcast networks</strong></li>
<li><strong>GPS navigation systems</strong></li></ol>
</section>

            <section class="content-section" id="characteristics">
                <h3 class="section-heading"><strong>Characteristics</strong></h3>
            
<ol class="content-list"><li><strong>Uses FIFO structure</strong> (queue)</li>
<li><strong>Finds shortest path</strong> in unweighted graphs</li>
<li><strong>Requires more memory</strong> than DFS for broad graphs</li>
<li><strong>Systematic level-by-level exploration</strong></li></ol>
</section>

            <section class="content-section" id="comparison-dfs-vs-bfs">
                <h3 class="section-heading"><strong>Comparison: DFS vs BFS</strong></h3>
            
<p class="paragraph">| Aspect | DFS | BFS |
|--------|-----|-----|
| Data Structure | Stack | Queue |
| Memory | O(depth) | O(width) |
| Shortest Path | Not guaranteed | Guaranteed (unweighted) |
| When to Use | Deep graphs, memory limited | Shortest path, level-order |</p>
</section>

            <section class="content-section" id="summary-of-brute-force-techniques">
                <h2 class="section-heading"><strong>Summary of Brute Force Techniques</strong></h2>
            
</section>

            <section class="content-section" id="methods-techniques-used">
                <h3 class="section-heading"><strong>Methods / Techniques Used</strong></h3>
            
<ol class="content-list"><li><strong>Direct Implementation</strong>: Straight from problem statement</li>
<li><strong>Systematic Search</strong>: Enumerate all possibilities</li>
<li><strong>Backtracking</strong>: Prune search space when constraints violated</li>
<li><strong>Branch and Bound</strong>: With bounding functions</li></ol>
</section>

            <section class="content-section" id="when-to-use-brute-force">
                <h3 class="section-heading"><strong>When to Use Brute Force</strong></h3>
            
<ol class="content-list"><li>Problem size is small</li>
<li>Simplicity is more important than efficiency</li>
<li>Need guaranteed optimal solution</li>
<li>As a baseline for comparison</li></ol>
</section>

            <section class="content-section" id="efficiency-classes-of-brute-force-algorithms">
                <h3 class="section-heading"><strong>Efficiency Classes of Brute Force Algorithms</strong></h3>
            
<ol class="content-list"><li><strong>Polynomial</strong>: Selection Sort (O(n²)), BFS/DFS (O(V+E))</li>
<li><strong>Exponential</strong>: TSP (O(n!))</li>
<li><strong>Factorial/Combinatorial</strong>: Subset problems (O(2ⁿ))</li></ol>
</section>

            <section class="content-section" id="real-world-constraints">
                <h3 class="section-heading"><strong>Real-world Constraints</strong></h3>
            
<ol class="content-list"><li><strong>Combinatorial explosion</strong> - Inputs too large</li>
<li><strong>Time constraints</strong> - Solutions needed in real-time</li>
<li><strong>Resource limitations</strong> - Memory and processing power constraints</li></ol>
<p class="paragraph">While theoretically correct, many brute force approaches are impractical for real-world problems due to:</p>
</section>

            <section class="content-section" id="unit-3-decrease-and-conquer-and-divide-and-conquer">
                <h1 class="section-heading"><strong>Unit 3: Decrease-and-Conquer and Divide-and-Conquer</strong></h1>
            
</section>

            <section class="content-section" id="1-decrease-and-conquer-introduction">
                <h2 class="section-heading"><strong>1. Decrease-and-Conquer: Introduction</strong></h2>
            
</section>

            <section class="content-section" id="meaning-concept">
                <h3 class="section-heading"><strong>Meaning / Concept</strong></h3>
            
<p class="paragraph"><strong>Decrease-and-Conquer</strong> is an algorithm design paradigm that solves a problem by reducing it to a smaller instance of the same problem, solving the smaller instance, and then extending the solution to the original problem.</p>
</section>

            <section class="content-section" id="formal-definition">
                <h3 class="section-heading"><strong>Formal Definition</strong></h3>
            
<p class="paragraph">According to <strong>Levitin</strong>, decrease-and-conquer works by establishing a relationship between a solution to a given instance of a problem and a solution to its smaller instance. The problem is reduced to a smaller one, solved recursively or iteratively, and then the solution is extended.</p>
</section>

            <section class="content-section" id="key-characteristics">
                <h3 class="section-heading"><strong>Key Characteristics</strong></h3>
            
<ol class="content-list"><li><strong>Reduces problem size</strong> by a constant or variable factor</li>
<li><strong>Solves the smaller instance</strong></li>
<li><strong>Extends the solution</strong> to solve the original problem</li></ol>
</section>

            <section class="content-section" id="three-major-variants">
                <h3 class="section-heading"><strong>Three Major Variants</strong></h3>
            
<ol class="content-list"><li><strong>Decrease-by-a-Constant</strong> (usually by 1)</li></ol>
<p class="paragraph">- Examples: Insertion Sort, Depth-First Search
   - Recurrence: T(n) = T(n-1) + f(n)</p>
<ol class="content-list"><li><strong>Decrease-by-a-Constant-Factor</strong> (usually by half)</li></ol>
<p class="paragraph">- Examples: Binary Search, Fake Coin problem
   - Recurrence: T(n) = T(n/2) + f(1)</p>
<ol class="content-list"><li><strong>Variable-Size-Decrease</strong></li></ol>
<p class="paragraph">- Examples: Euclid's algorithm, Interpolation Search
   - Reduction size varies at each step</p>
</section>

            <section class="content-section" id="need-purpose-applications">
                <h3 class="section-heading"><strong>Need / Purpose / Applications</strong></h3>
            
<ul class="content-list"><li><strong>Purpose</strong>: To systematically reduce problem complexity</li>
<li><strong>Applications</strong>: Sorting, searching, graph algorithms, combinatorial problems</li>
<li><strong>Advantages</strong>: Often simpler to implement than divide-and-conquer, good for problems with natural decreasing structure</li></ul>
</section>

            <section class="content-section" id="comparison-with-divide-and-conquer">
                <h3 class="section-heading"><strong>Comparison with Divide-and-Conquer</strong></h3>
            
<p class="paragraph">| Aspect | Decrease-and-Conquer | Divide-and-Conquer |
|--------|-------------------|------------------|
| <strong>Problem Division</strong> | Reduces to ONE smaller instance | Divides into TWO or MORE subproblems |
| <strong>Solution Combination</strong> | Extends solution from smaller instance | Combines solutions from all subproblems |
| <strong>Examples</strong> | Insertion Sort, Binary Search | Merge Sort, Quick Sort |</p>
<hr class="content-hr">
</section>

            <section class="content-section" id="2-insertion-sort">
                <h2 class="section-heading"><strong>2. Insertion Sort</strong></h2>
            
</section>

            <section class="content-section" id="meaning-concept">
                <h3 class="section-heading"><strong>Meaning / Concept</strong></h3>
            
<p class="paragraph">Insertion Sort is a simple comparison-based sorting algorithm that builds the final sorted array one element at a time. It is based on the <strong>decrease-by-one</strong> technique.</p>
</section>

            <section class="content-section" id="algorithm-step-by-step">
                <h3 class="section-heading"><strong>Algorithm (Step-by-Step)</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">Algorithm InsertionSort(A[0..n-1])
// Sorts a given array by insertion sort
// Input: An array A[0..n-1] of n comparable elements
// Output: Array A[0..n-1] sorted in non-decreasing order
for i ← 1 to n-1 do
    v ← A[i]
    j ← i - 1
    while j ≥ 0 and A[j] &gt; v do
        A[j+1] ← A[j]
        j ← j - 1
    A[j+1] ← v</code></pre>
            </div>
            
</section>

            <section class="content-section" id="explanation-of-the-algorithm">
                <h3 class="section-heading"><strong>Explanation of the Algorithm</strong></h3>
            
<ol class="content-list"><li>Start with the second element (i=1), considering the first element as a sorted subarray of size 1</li>
<li>For each subsequent element v = A[i]:</li></ol>
<ol class="content-list"><li>Repeat until all elements are processed</li></ol>
<p class="paragraph">- Find the correct position for v in the sorted subarray A[0..i-1]
   - Shift all elements greater than v one position to the right
   - Insert v into its correct position</p>
</section>

            <section class="content-section" id="decrease-and-conquer-perspective">
                <h3 class="section-heading"><strong>Decrease-and-Conquer Perspective</strong></h3>
            
<ul class="content-list"><li><strong>Problem</strong>: Sort array A[0..n-1]</li>
<li><strong>Smaller instance</strong>: Sort A[0..n-2]</li>
<li><strong>Extension</strong>: Insert A[n-1] into its proper place in the sorted A[0..n-2]</li></ul>
</section>

            <section class="content-section" id="example-problem-with-working-steps">
                <h3 class="section-heading"><strong>Example Problem with Working Steps</strong></h3>
            
<p class="paragraph"><strong>Problem</strong>: Sort [5, 2, 4, 6, 1, 3] using Insertion Sort</p>
<ul class="content-list"><li>Sorted: [5], Unsorted: [2, 4, 6, 1, 3]</li>
<li>2 < 5, shift 5 → [5, 5]</li>
<li>Insert 2 at position 0 → [2, 5, 4, 6, 1, 3]</li></ul>
<p class="paragraph"><strong>Pass 1 (i=1, v=2)</strong>:</p>
<ul class="content-list"><li>Sorted: [2, 5], Unsorted: [4, 6, 1, 3]</li>
<li>4 < 5, shift 5 → [2, 5, 5]</li>
<li>4 > 2, insert at position 1 → [2, 4, 5, 6, 1, 3]</li></ul>
<p class="paragraph"><strong>Pass 2 (i=2, v=4)</strong>:</p>
<ul class="content-list"><li>Sorted: [2, 4, 5], Unsorted: [6, 1, 3]</li>
<li>6 > 5, insert at position 3 → [2, 4, 5, 6, 1, 3]</li></ul>
<p class="paragraph"><strong>Pass 3 (i=3, v=6)</strong>:</p>
<ul class="content-list"><li>Sorted: [2, 4, 5, 6], Unsorted: [1, 3]</li>
<li>1 < 6, shift 6 → [2, 4, 5, 6, 6]</li>
<li>1 < 5, shift 5 → [2, 4, 5, 5, 6]</li>
<li>1 < 4, shift 4 → [2, 4, 4, 5, 6]</li>
<li>1 < 2, shift 2 → [2, 2, 4, 5, 6]</li>
<li>Insert 1 at position 0 → [1, 2, 4, 5, 6, 3]</li></ul>
<p class="paragraph"><strong>Pass 4 (i=4, v=1)</strong>:</p>
<ul class="content-list"><li>Sorted: [1, 2, 4, 5, 6], Unsorted: [3]</li>
<li>3 < 6, shift 6 → [1, 2, 4, 5, 6, 6]</li>
<li>3 < 5, shift 5 → [1, 2, 4, 5, 5, 6]</li>
<li>3 < 4, shift 4 → [1, 2, 4, 4, 5, 6]</li>
<li>3 > 2, insert at position 2 → [1, 2, 3, 4, 5, 6]</li></ul>
<p class="paragraph"><strong>Pass 5 (i=5, v=3)</strong>:</p>
<p class="paragraph"><strong>Final sorted array</strong>: [1, 2, 3, 4, 5, 6]</p>
</section>

            <section class="content-section" id="time-complexity">
                <h3 class="section-heading"><strong>Time Complexity</strong></h3>
            
<ul class="content-list"><li><strong>Best Case</strong>: O(n) - Array already sorted, only n-1 comparisons</li>
<li><strong>Average Case</strong>: Θ(n²) - Roughly n²/4 comparisons and shifts</li>
<li><strong>Worst Case</strong>: O(n²) - Array sorted in reverse order, n(n-1)/2 comparisons</li></ul>
</section>

            <section class="content-section" id="space-complexity">
                <h3 class="section-heading"><strong>Space Complexity</strong></h3>
            
<p class="paragraph">O(1) - <strong>In-place sorting</strong>, uses only constant extra space</p>
</section>

            <section class="content-section" id="functions-operations-involved">
                <h3 class="section-heading"><strong>Functions / Operations Involved</strong></h3>
            
<ol class="content-list"><li><strong>Comparison</strong>: <code>A[j] > v</code></li>
<li><strong>Assignment/Shifting</strong>: <code>A[j+1] ← A[j]</code></li>
<li><strong>Insertion</strong>: <code>A[j+1] ← v</code></li></ol>
</section>

            <section class="content-section" id="characteristics">
                <h3 class="section-heading"><strong>Characteristics</strong></h3>
            
<ol class="content-list"><li><strong>In-place sorting algorithm</strong></li>
<li><strong>Stable sort</strong> (preserves relative order of equal elements)</li>
<li><strong>Adaptive</strong>: Efficient for partially sorted arrays</li>
<li><strong>Online algorithm</strong>: Can sort list as it receives it</li></ol>
</section>

            <section class="content-section" id="advantages">
                <h3 class="section-heading"><strong>Advantages</strong></h3>
            
<ol class="content-list"><li>Simple to implement</li>
<li>Efficient for small datasets (n ≤ 50)</li>
<li>Efficient for nearly sorted arrays</li>
<li>Stable sorting</li>
<li>In-place (low memory usage)</li></ol>
</section>

            <section class="content-section" id="limitations">
                <h3 class="section-heading"><strong>Limitations</strong></h3>
            
<ol class="content-list"><li>Inefficient for large arrays (O(n²) average case)</li>
<li>Many element shifts required</li></ol>
</section>

            <section class="content-section" id="real-world-usage-examples">
                <h3 class="section-heading"><strong>Real-world Usage Examples</strong></h3>
            
<ul class="content-list"><li>Sorting small arrays in embedded systems</li>
<li>As the final step in more advanced algorithms like Timsort</li>
<li>When input is already nearly sorted</li>
<li>Educational purposes</li></ul>
<hr class="content-hr">
</section>

            <section class="content-section" id="3-topological-sorting">
                <h2 class="section-heading"><strong>3. Topological Sorting</strong></h2>
            
</section>

            <section class="content-section" id="meaning-concept">
                <h3 class="section-heading"><strong>Meaning / Concept</strong></h3>
            
<p class="paragraph">Topological sorting is a linear ordering of vertices in a Directed Acyclic Graph (DAG) such that for every directed edge (u → v), vertex u comes before vertex v in the ordering.</p>
</section>

            <section class="content-section" id="formal-definition">
                <h3 class="section-heading"><strong>Formal Definition</strong></h3>
            
<p class="paragraph">Given a DAG G = (V, E), a topological sort is a permutation of vertices such that if (u, v) ∈ E, then u appears before v in the permutation.</p>
</section>

            <section class="content-section" id="decrease-and-conquer-approach-source-removal-method">
                <h3 class="section-heading"><strong>Decrease-and-Conquer Approach (Source Removal Method)</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">Algorithm TopologicalSort_SourceRemoval(G)
// Produces a topological ordering of DAG G
// Input: DAG G = (V, E)
// Output: List L containing vertices in topological order
L ← empty list
Find a vertex with no incoming edges (a source)
while there exists a source vertex do
    remove the source vertex v and all its outgoing edges from G
    append v to L
if G has edges remaining then
    return error (graph has a cycle)
return L</code></pre>
            </div>
            
</section>

            <section class="content-section" id="dfs-based-algorithm-kahns-algorithm">
                <h3 class="section-heading"><strong>DFS-Based Algorithm (Kahn's Algorithm)</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">Algorithm TopologicalSort_Kahn(G)
// Kahn&#x27;s algorithm using indegree calculation
// Input: DAG G = (V, E)
// Output: Topological order of vertices
Compute indegree for each vertex
Initialize queue Q with all vertices having indegree 0
L ← empty list (will contain sorted elements)
count ← 0

while Q is not empty do
    v ← Q.dequeue()
    append v to L
    count ← count + 1
    
    for each neighbor w of v do
        indegree[w] ← indegree[w] - 1
        if indegree[w] = 0 then
            Q.enqueue(w)

if count ≠ |V| then
    return error (graph has a cycle)
return L</code></pre>
            </div>
            
</section>

            <section class="content-section" id="explanation-of-the-algorithm-source-removal-method">
                <h3 class="section-heading"><strong>Explanation of the Algorithm (Source Removal Method)</strong></h3>
            
<ol class="content-list"><li>Identify vertices with no incoming edges (sources)</li>
<li>Remove a source vertex and all its outgoing edges</li>
<li>Add the vertex to the topological order</li>
<li>Repeat until all vertices are removed</li>
<li>If no source can be found but graph still has vertices, cycle exists</li></ol>
</section>

            <section class="content-section" id="example-problem-with-working-steps">
                <h3 class="section-heading"><strong>Example Problem with Working Steps</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">    5 → 0 ← 4
    ↓       ↓
    2 → 3 → 1</code></pre>
            </div>
            
<p class="paragraph"><strong>Problem</strong>: Perform topological sort on this DAG:</p>
<ol class="content-list"><li>Initial sources: 4, 5 (no incoming edges)</li>
<li>Remove 4, edges: 4→0, 4→1. Order: [4]</li>
<li>Sources: 5</li>
<li>Remove 5, edges: 5→0, 5→2. Order: [4, 5]</li>
<li>Sources: 2</li>
<li>Remove 2, edge: 2→3. Order: [4, 5, 2]</li>
<li>Sources: 0, 3</li>
<li>Remove 0, no outgoing edges. Order: [4, 5, 2, 0]</li>
<li>Remove 3, edge: 3→1. Order: [4, 5, 2, 0, 3]</li>
<li>Remove 1, no outgoing edges. Order: [4, 5, 2, 0, 3, 1]</li></ol>
<p class="paragraph"><strong>Step-by-step (Source Removal)</strong>:</p>
<p class="paragraph"><strong>Valid topological orders</strong>: [4, 5, 0, 2, 3, 1] or [5, 4, 0, 2, 3, 1] etc.</p>
</section>

            <section class="content-section" id="time-complexity">
                <h3 class="section-heading"><strong>Time Complexity</strong></h3>
            
<ul class="content-list"><li><strong>Source Removal</strong>: O(V + E) with adjacency list</li>
<li><strong>DFS-based</strong>: O(V + E)</li></ul>
</section>

            <section class="content-section" id="space-complexity">
                <h3 class="section-heading"><strong>Space Complexity</strong></h3>
            
<p class="paragraph">O(V) - For storing indegrees, queue, and result list</p>
</section>

            <section class="content-section" id="applications">
                <h3 class="section-heading"><strong>Applications</strong></h3>
            
<ol class="content-list"><li><strong>Task scheduling</strong> with dependencies</li>
<li><strong>Course prerequisite</strong> ordering</li>
<li><strong>Instruction scheduling</strong> in compilers</li>
<li><strong>Build system</strong> dependency resolution (Makefiles)</li>
<li><strong>Event simulation</strong></li></ol>
</section>

            <section class="content-section" id="characteristics">
                <h3 class="section-heading"><strong>Characteristics</strong></h3>
            
<ol class="content-list"><li>Only works for <strong>Directed Acyclic Graphs (DAGs)</strong></li>
<li><strong>Not unique</strong> - A DAG can have multiple topological orders</li>
<li><strong>Cycle detection</strong>: If topological sort fails, graph contains cycle</li></ol>
<hr class="content-hr">
</section>

            <section class="content-section" id="4-divide-and-conquer-introduction">
                <h2 class="section-heading"><strong>4. Divide-and-Conquer: Introduction</strong></h2>
            
</section>

            <section class="content-section" id="meaning-concept">
                <h3 class="section-heading"><strong>Meaning / Concept</strong></h3>
            
<p class="paragraph"><strong>Divide-and-Conquer</strong> is a fundamental algorithm design paradigm that recursively breaks down a problem into two or more subproblems of the same or related type, until they become simple enough to be solved directly. The solutions to the subproblems are then combined to give a solution to the original problem.</p>
</section>

            <section class="content-section" id="formal-definition">
                <h3 class="section-heading"><strong>Formal Definition</strong></h3>
            
<ol class="content-list"><li><strong>Divide</strong>: Break the problem into several subproblems that are smaller instances of the same problem</li>
<li><strong>Conquer</strong>: Solve the subproblems recursively</li>
<li><strong>Combine</strong>: Combine the solutions to the subproblems into the solution for the original problem</li></ol>
<p class="paragraph">According to <strong>Cormen et al.</strong>, divide-and-conquer algorithm consists of three steps:</p>
</section>

            <section class="content-section" id="general-template">
                <h3 class="section-heading"><strong>General Template</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">Algorithm DivideAndConquer(P)
if P is small enough then
    solve P directly
else
    divide P into smaller subproblems P₁, P₂, ..., Pₖ
    for i = 1 to k do
        Sᵢ ← DivideAndConquer(Pᵢ)
    combine S₁, S₂, ..., Sₖ to get solution S for P
return S</code></pre>
            </div>
            
</section>

            <section class="content-section" id="recurrence-relations">
                <h3 class="section-heading"><strong>Recurrence Relations</strong></h3>
            
<ol class="content-list"><li><strong>T(n) = aT(n/b) + f(n)</strong> - Master Theorem applicable</li>
<li><strong>T(n) = T(n-1) + T(n-2) + ...</strong> - Decrease-and-conquer</li>
<li><strong>T(n) = 2T(n/2) + Θ(n)</strong> - Merge Sort recurrence</li></ol>
<p class="paragraph">Common recurrence forms:</p>
</section>

            <section class="content-section" id="need-purpose-applications">
                <h3 class="section-heading"><strong>Need / Purpose / Applications</strong></h3>
            
<ul class="content-list"><li><strong>Purpose</strong>: To solve complex problems by breaking them into manageable pieces</li>
<li><strong>Advantages</strong>: Often leads to efficient algorithms, naturally parallelizable</li>
<li><strong>Applications</strong>: Sorting, searching, matrix multiplication, FFT, computational geometry</li></ul>
</section>

            <section class="content-section" id="three-steps-in-detail">
                <h3 class="section-heading"><strong>Three Steps in Detail</strong></h3>
            
<ol class="content-list"><li><strong>Divide Step</strong>:</li></ol>
<p class="paragraph">- Partition the problem into disjoint subproblems
   - Typically divides input into equal or nearly equal parts</p>
<ol class="content-list"><li><strong>Conquer Step</strong>:</li></ol>
<p class="paragraph">- Solve subproblems recursively
   - Base case: When subproblem size is small enough, solve directly</p>
<ol class="content-list"><li><strong>Combine Step</strong>:</li></ol>
<p class="paragraph">- Merge solutions of subproblems
   - This step distinguishes divide-and-conquer from decrease-and-conquer</p>
</section>

            <section class="content-section" id="examples-of-divide-and-conquer-algorithms">
                <h3 class="section-heading"><strong>Examples of Divide-and-Conquer Algorithms</strong></h3>
            
<ol class="content-list"><li><strong>Merge Sort</strong>: Divide array into halves, sort recursively, merge</li>
<li><strong>Quick Sort</strong>: Partition array, sort subarrays recursively</li>
<li><strong>Binary Search</strong>: Divide search space in half</li>
<li><strong>Strassen's Matrix Multiplication</strong>: Divide matrices, multiply recursively</li>
<li><strong>Closest Pair of Points</strong>: Divide plane, find closest pairs recursively</li></ol>
<hr class="content-hr">
</section>

            <section class="content-section" id="5-merge-sort">
                <h2 class="section-heading"><strong>5. Merge Sort</strong></h2>
            
</section>

            <section class="content-section" id="meaning-concept">
                <h3 class="section-heading"><strong>Meaning / Concept</strong></h3>
            
<p class="paragraph">Merge Sort is a comparison-based sorting algorithm that uses the divide-and-conquer paradigm. It divides the array into two halves, sorts each half recursively, and then merges the two sorted halves.</p>
</section>

            <section class="content-section" id="algorithm-step-by-step">
                <h3 class="section-heading"><strong>Algorithm (Step-by-Step)</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">Algorithm MergeSort(A[0..n-1])
// Sorts array A by merge sort
// Input: Array A[0..n-1] of orderable elements
// Output: Array A[0..n-1] sorted in non-decreasing order
if n &gt; 1 then
    // Divide
    copy A[0..⌊n/2⌋ - 1] to B[0..⌊n/2⌋ - 1]
    copy A[⌊n/2⌋..n-1] to C[0..⌈n/2⌉ - 1]
    
    // Conquer
    MergeSort(B)
    MergeSort(C)
    
    // Combine
    Merge(B, C, A)

Algorithm Merge(B[0..p-1], C[0..q-1], A[0..p+q-1])
// Merges two sorted arrays into one sorted array
// Input: Sorted arrays B and C
// Output: Sorted array A containing elements of B and C
i ← 0; j ← 0; k ← 0
while i &lt; p and j &lt; q do
    if B[i] ≤ C[j]
        A[k] ← B[i]; i ← i + 1
    else
        A[k] ← C[j]; j ← j + 1
    k ← k + 1
    
if i = p
    copy C[j..q-1] to A[k..p+q-1]
else
    copy B[i..p-1] to A[k..p+q-1]</code></pre>
            </div>
            
</section>

            <section class="content-section" id="explanation-of-the-algorithm">
                <h3 class="section-heading"><strong>Explanation of the Algorithm</strong></h3>
            
<ol class="content-list"><li><strong>Divide</strong>: Split the array into two equal (or nearly equal) halves</li>
<li><strong>Conquer</strong>: Recursively sort each half using Merge Sort</li>
<li><strong>Combine</strong>: Merge the two sorted halves into a single sorted array using the Merge procedure</li></ol>
</section>

            <section class="content-section" id="divide-and-conquer-analysis">
                <h3 class="section-heading"><strong>Divide-and-Conquer Analysis</strong></h3>
            
<ul class="content-list"><li><strong>Divide</strong>: O(1) - Just compute middle index</li>
<li><strong>Conquer</strong>: 2T(n/2) - Two recursive calls on halves</li>
<li><strong>Combine</strong>: O(n) - Merging two halves</li></ul>
<p class="paragraph"><strong>Recurrence</strong>: T(n) = 2T(n/2) + Θ(n)</p>
</section>

            <section class="content-section" id="example-problem-with-working-steps">
                <h3 class="section-heading"><strong>Example Problem with Working Steps</strong></h3>
            
<p class="paragraph"><strong>Problem</strong>: Sort [38, 27, 43, 3, 9, 82, 10] using Merge Sort</p>

            <div class="code-block">
                <pre><code class="language-text">Level 0: [38, 27, 43, 3, 9, 82, 10]
        Divide: [38, 27, 43] and [3, 9, 82, 10]

Level 1: [38, 27, 43]
        Divide: [38] and [27, 43]
Level 1: [3, 9, 82, 10]
        Divide: [3, 9] and [82, 10]

Level 2: [27, 43]
        Divide: [27] and [43]
Level 2: [3, 9]
        Divide: [3] and [9]
Level 2: [82, 10]
        Divide: [82] and [10]</code></pre>
            </div>
            
<p class="paragraph"><strong>Recursive Division</strong>:</p>

            <div class="code-block">
                <pre><code class="language-text">[38] + [27, 43] → Merge → [27, 38, 43]
[3] + [9] → Merge → [3, 9]
[82] + [10] → Merge → [10, 82]

[27, 38, 43] + [3, 9, 10, 82] → Merge → [3, 9, 10, 27, 38, 43, 82]</code></pre>
            </div>
            
<p class="paragraph"><strong>Merging Phase</strong>:</p>
<ul class="content-list"><li>Compare 27 and 3 → Take 3</li>
<li>Compare 27 and 9 → Take 9</li>
<li>Compare 27 and 10 → Take 10</li>
<li>Compare 27 and 82 → Take 27</li>
<li>Compare 38 and 82 → Take 38</li>
<li>Compare 43 and 82 → Take 43</li>
<li>Take remaining 82</li></ul>
<p class="paragraph"><strong>Detailed Merge of [27, 38, 43] and [3, 9, 10, 82]</strong>:</p>
<p class="paragraph"><strong>Final sorted array</strong>: [3, 9, 10, 27, 38, 43, 82]</p>
</section>

            <section class="content-section" id="time-complexity">
                <h3 class="section-heading"><strong>Time Complexity</strong></h3>
            
<ul class="content-list"><li><strong>Best Case</strong>: O(n log n) - Already sorted array</li>
<li><strong>Average Case</strong>: Θ(n log n)</li>
<li><strong>Worst Case</strong>: O(n log n) - All cases have same complexity</li></ul>
<p class="paragraph"><strong>Solving Recurrence</strong>:
T(n) = 2T(n/2) + cn
     = 2[2T(n/4) + c(n/2)] + cn = 4T(n/4) + 2cn
     = 8T(n/8) + 3cn
     = 2ᵏT(n/2ᵏ) + kcn
When n/2ᵏ = 1 ⇒ k = log₂n
T(n) = nT(1) + cn log₂n = O(n log n)</p>
</section>

            <section class="content-section" id="space-complexity">
                <h3 class="section-heading"><strong>Space Complexity</strong></h3>
            
<p class="paragraph">O(n) - Requires temporary arrays for merging</p>
</section>

            <section class="content-section" id="characteristics">
                <h3 class="section-heading"><strong>Characteristics</strong></h3>
            
<ol class="content-list"><li><strong>Stable sort</strong> - Preserves relative order of equal elements</li>
<li><strong>Not in-place</strong> - Requires O(n) additional memory</li>
<li><strong>External sorting</strong> - Can sort data too large for memory</li>
<li><strong>Guaranteed O(n log n)</strong> performance</li></ol>
</section>

            <section class="content-section" id="advantages">
                <h3 class="section-heading"><strong>Advantages</strong></h3>
            
<ol class="content-list"><li>Predictable O(n log n) time in all cases</li>
<li>Stable sorting</li>
<li>Good for linked lists (requires only O(1) extra space)</li>
<li>Suitable for external sorting</li></ol>
</section>

            <section class="content-section" id="limitations">
                <h3 class="section-heading"><strong>Limitations</strong></h3>
            
<ol class="content-list"><li>Requires O(n) additional memory</li>
<li>Slower than Quick Sort for arrays in practice due to copying overhead</li></ol>
</section>

            <section class="content-section" id="real-world-usage-examples">
                <h3 class="section-heading"><strong>Real-world Usage Examples</strong></h3>
            
<ul class="content-list"><li>External sorting of large files</li>
<li>Sorting linked lists</li>
<li>As a component in more complex algorithms (TimSort)</li>
<li>When stable sorting is required</li></ul>
<hr class="content-hr">
</section>

            <section class="content-section" id="6-quick-sort">
                <h2 class="section-heading"><strong>6. Quick Sort</strong></h2>
            
</section>

            <section class="content-section" id="meaning-concept">
                <h3 class="section-heading"><strong>Meaning / Concept</strong></h3>
            
<p class="paragraph">Quick Sort is a highly efficient comparison-based sorting algorithm that uses divide-and-conquer. It works by selecting a 'pivot' element and partitioning the array so that elements less than pivot come before it, and elements greater come after it. The subarrays are then sorted recursively.</p>
</section>

            <section class="content-section" id="algorithm-step-by-step">
                <h3 class="section-heading"><strong>Algorithm (Step-by-Step)</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">Algorithm QuickSort(A[l..r])
// Sorts subarray A[l..r] by quicksort
// Input: Subarray A[l..r] of A[0..n-1]
// Output: Subarray A[l..r] sorted in non-decreasing order
if l &lt; r then
    s ← Partition(A[l..r])  // s is pivot&#x27;s final position
    QuickSort(A[l..s-1])
    QuickSort(A[s+1..r])

Algorithm Partition(A[l..r])
// Partitions subarray using first element as pivot
// Input: Subarray A[l..r] of A[0..n-1]
// Output: Final position of pivot element
p ← A[l]
i ← l
j ← r + 1

repeat
    repeat i ← i + 1 until A[i] ≥ p
    repeat j ← j - 1 until A[j] ≤ p
    swap A[i] and A[j]
until i ≥ j

swap A[i] and A[j]  // undo last swap when i ≥ j
swap A[l] and A[j]
return j</code></pre>
            </div>
            
</section>

            <section class="content-section" id="lomuto-partition-scheme-simpler">
                <h3 class="section-heading"><strong>Lomuto Partition Scheme (Simpler)</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">Algorithm Partition_Lomuto(A[l..r])
// Lomuto partition scheme
pivot ← A[r]
i ← l - 1
for j ← l to r-1 do
    if A[j] ≤ pivot then
        i ← i + 1
        swap A[i] and A[j]
swap A[i+1] and A[r]
return i+1</code></pre>
            </div>
            
</section>

            <section class="content-section" id="explanation-of-the-algorithm">
                <h3 class="section-heading"><strong>Explanation of the Algorithm</strong></h3>
            
<ol class="content-list"><li><strong>Divide</strong>: Choose a pivot element and partition the array into two subarrays:</li></ol>
<ol class="content-list"><li><strong>Conquer</strong>: Recursively sort the left and right subarrays</li>
<li><strong>Combine</strong>: Nothing to combine (subarrays are already in place)</li></ol>
<p class="paragraph">- Left: elements ≤ pivot
   - Right: elements > pivot</p>
</section>

            <section class="content-section" id="divide-and-conquer-analysis">
                <h3 class="section-heading"><strong>Divide-and-Conquer Analysis</strong></h3>
            
<ul class="content-list"><li><strong>Divide</strong>: O(n) - Partitioning step</li>
<li><strong>Conquer</strong>: T(k) + T(n-k-1) where k is size of left partition</li>
<li><strong>Combine</strong>: O(1) - No work needed</li></ul>
</section>

            <section class="content-section" id="example-problem-with-working-steps">
                <h3 class="section-heading"><strong>Example Problem with Working Steps</strong></h3>
            
<p class="paragraph"><strong>Problem</strong>: Sort [10, 80, 30, 90, 40, 50, 70] using Quick Sort with last element as pivot</p>
<ul class="content-list"><li>Initialize: i = -1, pivot = 70</li>
<li>j=0: 10 ≤ 70 → i=0, swap A[0] with A[0] → [10, 80, 30, 90, 40, 50, 70]</li>
<li>j=1: 80 > 70 → no swap</li>
<li>j=2: 30 ≤ 70 → i=1, swap A[1] and A[2] → [10, 30, 80, 90, 40, 50, 70]</li>
<li>j=3: 90 > 70 → no swap</li>
<li>j=4: 40 ≤ 70 → i=2, swap A[2] and A[4] → [10, 30, 40, 90, 80, 50, 70]</li>
<li>j=5: 50 ≤ 70 → i=3, swap A[3] and A[5] → [10, 30, 40, 50, 80, 90, 70]</li>
<li>Final: swap A[i+1]=A[4] with pivot A[6] → [10, 30, 40, 50, 70, 90, 80]</li>
<li>Pivot position = 4</li></ul>
<p class="paragraph"><strong>First Partition (pivot = 70, Lomuto scheme)</strong>:</p>
<ul class="content-list"><li>Left: QuickSort([10, 30, 40, 50])</li>
<li>Right: QuickSort([90, 80])</li></ul>
<p class="paragraph"><strong>Recursive calls</strong>:</p>
<p class="paragraph"><strong>Continue recursively until fully sorted</strong>: [10, 30, 40, 50, 70, 80, 90]</p>
</section>

            <section class="content-section" id="time-complexity">
                <h3 class="section-heading"><strong>Time Complexity</strong></h3>
            
<ul class="content-list"><li><strong>Best Case</strong>: O(n log n) - Pivot always divides array into equal halves</li>
<li><strong>Average Case</strong>: Θ(n log n) - Expected performance with random pivot</li>
<li><strong>Worst Case</strong>: O(n²) - Pivot is smallest or largest element (already sorted or reverse sorted array)</li></ul>
<p class="paragraph"><strong>Best Case Recurrence</strong>: T(n) = 2T(n/2) + Θ(n) = O(n log n)
<strong>Worst Case Recurrence</strong>: T(n) = T(n-1) + Θ(n) = O(n²)</p>
</section>

            <section class="content-section" id="space-complexity">
                <h3 class="section-heading"><strong>Space Complexity</strong></h3>
            
<ul class="content-list"><li><strong>Worst Case</strong>: O(n) - Due to recursion stack in unbalanced partitions</li>
<li><strong>Best Case</strong>: O(log n) - Balanced partitions</li></ul>
</section>

            <section class="content-section" id="pivot-selection-strategies">
                <h3 class="section-heading"><strong>Pivot Selection Strategies</strong></h3>
            
<ol class="content-list"><li><strong>First element</strong> - Simple but vulnerable to worst case</li>
<li><strong>Last element</strong> - Simple but vulnerable to worst case</li>
<li><strong>Random element</strong> - Good expected performance</li>
<li><strong>Median-of-three</strong> - First, middle, last - resists worst case</li></ol>
</section>

            <section class="content-section" id="characteristics">
                <h3 class="section-heading"><strong>Characteristics</strong></h3>
            
<ol class="content-list"><li><strong>In-place sorting</strong> - O(log n) extra space for recursion stack</li>
<li><strong>Not stable</strong> - May change relative order of equal elements</li>
<li><strong>Cache efficient</strong> - Good locality of reference</li>
<li><strong>Practically fast</strong> - Often faster than other O(n log n) algorithms</li></ol>
</section>

            <section class="content-section" id="advantages">
                <h3 class="section-heading"><strong>Advantages</strong></h3>
            
<ol class="content-list"><li>Very fast in practice (good cache performance)</li>
<li>In-place sorting (memory efficient)</li>
<li>No extra memory for merging</li>
<li>Can be optimized (tail recursion, insertion sort for small subarrays)</li></ol>
</section>

            <section class="content-section" id="limitations">
                <h3 class="section-heading"><strong>Limitations</strong></h3>
            
<ol class="content-list"><li>Worst-case O(n²) time (though avoidable with good pivot selection)</li>
<li>Not stable</li>
<li>Performance depends on pivot selection</li></ol>
</section>

            <section class="content-section" id="real-world-usage-examples">
                <h3 class="section-heading"><strong>Real-world Usage Examples</strong></h3>
            
<ul class="content-list"><li>Standard library sort in C (qsort), C++ (std::sort)</li>
<li>Database indexing</li>
<li>Numerical computations</li>
<li>When in-place sorting is critical</li></ul>
<hr class="content-hr">
</section>

            <section class="content-section" id="7-binary-search">
                <h2 class="section-heading"><strong>7. Binary Search</strong></h2>
            
</section>

            <section class="content-section" id="meaning-concept">
                <h3 class="section-heading"><strong>Meaning / Concept</strong></h3>
            
<p class="paragraph">Binary Search is an efficient algorithm for finding an item from a sorted list of items. It works by repeatedly dividing in half the portion of the list that could contain the item, until you've narrowed down the possible locations to just one.</p>
</section>

            <section class="content-section" id="algorithm-step-by-step">
                <h3 class="section-heading"><strong>Algorithm (Step-by-Step)</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">Algorithm BinarySearch(A[0..n-1], K)
// Implements binary search recursively
// Input: Sorted array A[0..n-1] and search key K
// Output: Index of K in A or -1 if not found
if n = 0 return -1
else
    m ← ⌊(n-1)/2⌋
    if K = A[m] return m
    else if K &lt; A[m]
        return BinarySearch(A[0..m-1], K)
    else
        return BinarySearch(A[m+1..n-1], K)

// Iterative version
Algorithm BinarySearch_Iterative(A[0..n-1], K)
l ← 0
r ← n-1
while l ≤ r do
    m ← ⌊(l + r)/2⌋
    if K = A[m] return m
    else if K &lt; A[m]
        r ← m - 1
    else
        l ← m + 1
return -1</code></pre>
            </div>
            
</section>

            <section class="content-section" id="explanation-of-the-algorithm">
                <h3 class="section-heading"><strong>Explanation of the Algorithm</strong></h3>
            
<ol class="content-list"><li>Compare the search key K with the middle element of the array</li>
<li>If they match, return the middle index</li>
<li>If K is less than the middle element, search in the left half</li>
<li>If K is greater than the middle element, search in the right half</li>
<li>Repeat until found or search space is empty</li></ol>
</section>

            <section class="content-section" id="divide-and-conquer-perspective">
                <h3 class="section-heading"><strong>Divide-and-Conquer Perspective</strong></h3>
            
<ul class="content-list"><li><strong>Divide</strong>: Check middle element, decide which half to search</li>
<li><strong>Conquer</strong>: Search the chosen half recursively</li>
<li><strong>Combine</strong>: Return the result (no combination needed)</li></ul>
<p class="paragraph"><strong>Recurrence</strong>: T(n) = T(n/2) + Θ(1)</p>
</section>

            <section class="content-section" id="example-problem-with-working-steps">
                <h3 class="section-heading"><strong>Example Problem with Working Steps</strong></h3>
            
<p class="paragraph"><strong>Problem</strong>: Search for 23 in sorted array [2, 5, 8, 12, 16, 23, 38, 56, 72, 91]</p>
<ul class="content-list"><li>23 > 16 → search right: l=5, r=9</li></ul>
<p class="paragraph"><strong>Step 1</strong>: l=0, r=9, m=4, A[4]=16</p>
<ul class="content-list"><li>23 < 56 → search left: l=5, r=6</li></ul>
<p class="paragraph"><strong>Step 2</strong>: l=5, r=9, m=7, A[7]=56</p>
<ul class="content-list"><li>Found! Return index 5</li></ul>
<p class="paragraph"><strong>Step 3</strong>: l=5, r=6, m=5, A[5]=23</p>
</section>

            <section class="content-section" id="time-complexity">
                <h3 class="section-heading"><strong>Time Complexity</strong></h3>
            
<ul class="content-list"><li><strong>Best Case</strong>: O(1) - Key found at first middle element</li>
<li><strong>Average Case</strong>: Θ(log n)</li>
<li><strong>Worst Case</strong>: O(log n) - Key not present or at last position</li></ul>
<p class="paragraph"><strong>Solving Recurrence</strong>:
T(n) = T(n/2) + 1
     = T(n/4) + 1 + 1
     = T(n/2ᵏ) + k
When n/2ᵏ = 1 ⇒ k = log₂n
T(n) = 1 + log₂n = O(log n)</p>
</section>

            <section class="content-section" id="space-complexity">
                <h3 class="section-heading"><strong>Space Complexity</strong></h3>
            
<ul class="content-list"><li><strong>Iterative</strong>: O(1)</li>
<li><strong>Recursive</strong>: O(log n) due to recursion stack</li></ul>
</section>

            <section class="content-section" id="characteristics">
                <h3 class="section-heading"><strong>Characteristics</strong></h3>
            
<ol class="content-list"><li><strong>Requires sorted array</strong> as precondition</li>
<li><strong>Divide-and-conquer</strong> algorithm (decrease-by-half)</li>
<li><strong>Much faster than linear search</strong> for large arrays</li>
<li><strong>Not suitable for linked lists</strong> (needs random access)</li></ol>
</section>

            <section class="content-section" id="applications">
                <h3 class="section-heading"><strong>Applications</strong></h3>
            
<ol class="content-list"><li>Searching in databases</li>
<li>Dictionary lookups</li>
<li>Number guessing games</li>
<li>Finding roots of equations</li>
<li>Debugging (binary search through code changes)</li></ol>
</section>

            <section class="content-section" id="variants">
                <h3 class="section-heading"><strong>Variants</strong></h3>
            
<ol class="content-list"><li><strong>Lower bound search</strong> - Find first occurrence</li>
<li><strong>Upper bound search</strong> - Find last occurrence</li>
<li><strong>Ternary search</strong> - Divide into three parts</li>
<li><strong>Exponential search</strong> - For unbounded/infinite arrays</li></ol>
<hr class="content-hr">
</section>

            <section class="content-section" id="8-binary-tree-traversals-and-related-properties">
                <h2 class="section-heading"><strong>8. Binary Tree Traversals and Related Properties</strong></h2>
            
</section>

            <section class="content-section" id="meaning-concept">
                <h3 class="section-heading"><strong>Meaning / Concept</strong></h3>
            
<p class="paragraph">Binary tree traversal refers to the process of visiting (processing) each node in a binary tree exactly once in a specific order. Different traversal orders serve different purposes.</p>
</section>

            <section class="content-section" id="binary-tree-structure">
                <h3 class="section-heading"><strong>Binary Tree Structure</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">struct Node {
    data
    leftChild (pointer to left subtree)
    rightChild (pointer to right subtree)
}</code></pre>
            </div>
            
</section>

            <section class="content-section" id="three-fundamental-traversals">
                <h3 class="section-heading"><strong>Three Fundamental Traversals</strong></h3>
            
</section>

            <section class="content-section" id="1-preorder-traversal-root-left-right">
                <h4 class="section-heading"><strong>1. Preorder Traversal (Root-Left-Right)</strong></h4>
            

            <div class="code-block">
                <pre><code class="language-text">Algorithm Preorder(root)
if root ≠ null then
    visit(root)
    Preorder(root.left)
    Preorder(root.right)</code></pre>
            </div>
            
<p class="paragraph"><strong>Order</strong>: Root → Left subtree → Right subtree
<strong>Applications</strong>: Creating copy of tree, prefix expression evaluation</p>
</section>

            <section class="content-section" id="2-inorder-traversal-left-root-right">
                <h4 class="section-heading"><strong>2. Inorder Traversal (Left-Root-Right)</strong></h4>
            

            <div class="code-block">
                <pre><code class="language-text">Algorithm Inorder(root)
if root ≠ null then
    Inorder(root.left)
    visit(root)
    Inorder(root.right)</code></pre>
            </div>
            
<p class="paragraph"><strong>Order</strong>: Left subtree → Root → Right subtree
<strong>Applications</strong>: Produces sorted order for Binary Search Trees</p>
</section>

            <section class="content-section" id="3-postorder-traversal-left-right-root">
                <h4 class="section-heading"><strong>3. Postorder Traversal (Left-Right-Root)</strong></h4>
            

            <div class="code-block">
                <pre><code class="language-text">Algorithm Postorder(root)
if root ≠ null then
    Postorder(root.left)
    Postorder(root.right)
    visit(root)</code></pre>
            </div>
            
<p class="paragraph"><strong>Order</strong>: Left subtree → Right subtree → Root
<strong>Applications</strong>: Deleting tree, postfix expression evaluation</p>
</section>

            <section class="content-section" id="example-problem-with-working-steps">
                <h3 class="section-heading"><strong>Example Problem with Working Steps</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">        A
       / \
      B   C
     / \   \
    D   E   F</code></pre>
            </div>
            
<p class="paragraph"><strong>Problem</strong>: Traverse this binary tree:</p>
<ol class="content-list"><li>Visit A</li>
<li>Traverse left subtree (B, D, E)</li>
<li>Traverse right subtree (C, F)</li></ol>
<p class="paragraph"><strong>Preorder (Root-Left-Right)</strong>:
<strong>Result</strong>: A → B → D → E → C → F</p>
<ol class="content-list"><li>Traverse left subtree of A (B's subtree)</li></ol>
<ol class="content-list"><li>Visit A</li>
<li>Traverse right subtree of A (C's subtree)</li></ol>
<p class="paragraph"><strong>Inorder (Left-Root-Right)</strong>:
   - Traverse left of B (D)
   - Visit B
   - Traverse right of B (E)
   - Traverse left of C (null)
   - Visit C
   - Traverse right of C (F)
<strong>Result</strong>: D → B → E → A → C → F</p>
<ol class="content-list"><li>Traverse left subtree (D, E, B)</li>
<li>Traverse right subtree (F, C)</li>
<li>Visit A</li></ol>
<p class="paragraph"><strong>Postorder (Left-Right-Root)</strong>:
<strong>Result</strong>: D → E → B → F → C → A</p>
</section>

            <section class="content-section" id="level-order-traversal-breadth-first">
                <h3 class="section-heading"><strong>Level Order Traversal (Breadth-First)</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">Algorithm LevelOrder(root)
if root = null return
queue ← empty queue
queue.enqueue(root)
while queue not empty do
    current ← queue.dequeue()
    visit(current)
    if current.left ≠ null
        queue.enqueue(current.left)
    if current.right ≠ null
        queue.enqueue(current.right)</code></pre>
            </div>
            
<p class="paragraph"><strong>Result for example</strong>: A → B → C → D → E → F</p>
</section>

            <section class="content-section" id="time-complexity">
                <h3 class="section-heading"><strong>Time Complexity</strong></h3>
            
<ul class="content-list"><li>Each node visited exactly once</li>
<li>Each edge traversed exactly twice</li></ul>
<p class="paragraph">For all traversals: O(n) where n = number of nodes</p>
</section>

            <section class="content-section" id="space-complexity">
                <h3 class="section-heading"><strong>Space Complexity</strong></h3>
            
<ul class="content-list"><li><strong>Depth-first traversals</strong>: O(h) where h = height of tree</li>
<li><strong>Level-order</strong>: O(w) where w = maximum width of tree</li></ul>
</section>

            <section class="content-section" id="divide-and-conquer-perspective">
                <h3 class="section-heading"><strong>Divide-and-Conquer Perspective</strong></h3>
            
<ul class="content-list"><li><strong>Divide</strong>: Split into left and right subtrees</li>
<li><strong>Conquer</strong>: Traverse left and right subtrees recursively</li>
<li><strong>Combine</strong>: Process root (order differs by traversal type)</li></ul>
<p class="paragraph">Binary tree traversals are classic divide-and-conquer algorithms:</p>
</section>

            <section class="content-section" id="properties-of-binary-trees">
                <h3 class="section-heading"><strong>Properties of Binary Trees</strong></h3>
            
<ol class="content-list"><li><strong>Maximum number of nodes at level i</strong>: 2ⁱ</li>
<li><strong>Maximum number of nodes in tree of height h</strong>: 2ʰ⁺¹ - 1</li>
<li><strong>Minimum height of tree with n nodes</strong>: ⌈log₂(n+1)⌉ - 1</li>
<li><strong>Number of leaf nodes in full binary tree</strong>: (n+1)/2</li>
<li><strong>Number of null links in tree with n nodes</strong>: n+1</li></ol>
</section>

            <section class="content-section" id="binary-search-tree-bst-properties">
                <h3 class="section-heading"><strong>Binary Search Tree (BST) Properties</strong></h3>
            
<ol class="content-list"><li><strong>Inorder traversal of BST gives sorted order</strong></li>
<li><strong>Search, Insert, Delete</strong>: O(h) time where h = height</li></ol>
<p class="paragraph">- Balanced BST: O(log n)
   - Skewed BST: O(n)</p>
</section>

            <section class="content-section" id="applications">
                <h3 class="section-heading"><strong>Applications</strong></h3>
            
<ol class="content-list"><li><strong>Expression trees</strong> for compiler design</li>
<li><strong>File system</strong> hierarchy representation</li>
<li><strong>Database indexing</strong> (B-trees, AVL trees)</li>
<li><strong>Decision trees</strong> in machine learning</li>
<li><strong>Game trees</strong> in artificial intelligence</li></ol>
</section>

            <section class="content-section" id="real-world-usage-examples">
                <h3 class="section-heading"><strong>Real-world Usage Examples</strong></h3>
            
<ul class="content-list"><li><strong>File systems</strong>: Directory structure traversal</li>
<li><strong>Document Object Model (DOM)</strong>: Web page element traversal</li>
<li><strong>Compiler construction</strong>: Syntax tree traversal</li>
<li><strong>Database systems</strong>: Index tree traversal</li></ul>
</section>

            <section class="content-section" id="unit-4-greedy-technique-and-complexity-theory">
                <h1 class="section-heading"><strong>Unit 4: Greedy Technique and Complexity Theory</strong></h1>
            
</section>

            <section class="content-section" id="1-greedy-technique-introduction">
                <h2 class="section-heading"><strong>1. Greedy Technique: Introduction</strong></h2>
            
</section>

            <section class="content-section" id="meaning-concept">
                <h3 class="section-heading"><strong>Meaning / Concept</strong></h3>
            
<p class="paragraph">The <strong>Greedy Technique</strong> is an algorithmic paradigm that builds up a solution piece by piece, always choosing the next piece that offers the most immediate benefit. It makes locally optimal choices at each stage with the hope of finding a global optimum.</p>
</section>

            <section class="content-section" id="formal-definition">
                <h3 class="section-heading"><strong>Formal Definition</strong></h3>
            
<p class="paragraph">According to <strong>Cormen et al.</strong>, a greedy algorithm always makes the choice that looks best at the moment. That is, it makes a locally optimal choice in the hope that this choice will lead to a globally optimal solution.</p>
<p class="paragraph"><strong>Levitin</strong> defines it as an algorithm that constructs a solution through a sequence of steps, each expanding a partially constructed solution obtained so far, until a complete solution to the problem is reached. At each step, the choice made must be feasible, locally optimal, and irrevocable.</p>
</section>

            <section class="content-section" id="key-characteristics">
                <h3 class="section-heading"><strong>Key Characteristics</strong></h3>
            
<ol class="content-list"><li><strong>Greedy Choice Property</strong>: A globally optimal solution can be arrived at by making a locally optimal (greedy) choice.</li>
<li><strong>Optimal Substructure</strong>: An optimal solution to the problem contains within it optimal solutions to subproblems.</li>
<li><strong>Irrevocable Decisions</strong>: Once a choice is made, it cannot be changed later.</li>
<li><strong>Top-down Approach</strong>: Works from the top, making one greedy choice after another.</li></ol>
</section>

            <section class="content-section" id="general-structure">
                <h3 class="section-heading"><strong>General Structure</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">Algorithm Greedy(C)
// C is the set of candidates
S ← ∅  // S will contain the solution
while C ≠ ∅ and not Solution(S) do
    x ← Select(C)      // Select the best candidate
    C ← C - {x}
    if Feasible(S ∪ {x}) then
        S ← S ∪ {x}
if Solution(S) then
    return S
else
    return &quot;no solution&quot;</code></pre>
            </div>
            
</section>

            <section class="content-section" id="need-purpose-applications">
                <h3 class="section-heading"><strong>Need / Purpose / Applications</strong></h3>
            
<ul class="content-list"><li><strong>Purpose</strong>: To solve optimization problems efficiently where local optimal choices lead to global optimum.</li>
<li><strong>When to Use</strong>: When the problem exhibits greedy choice property and optimal substructure.</li>
<li><strong>Applications</strong>: Minimum Spanning Trees, Shortest Paths, Huffman Coding, Activity Selection, Fractional Knapsack.</li></ul>
</section>

            <section class="content-section" id="proof-techniques-for-greedy-algorithms">
                <h3 class="section-heading"><strong>Proof Techniques for Greedy Algorithms</strong></h3>
            
<ol class="content-list"><li><strong>Greedy Stays Ahead</strong>: Show that greedy algorithm is always at least as good as any other at each step.</li>
<li><strong>Exchange Argument</strong>: Show any optimal solution can be transformed to the greedy solution without making it worse.</li>
<li><strong>Matroid Theory</strong>: Formal mathematical framework for greedy algorithms.</li></ol>
</section>

            <section class="content-section" id="advantages">
                <h3 class="section-heading"><strong>Advantages</strong></h3>
            
<ol class="content-list"><li><strong>Simple and easy to implement</strong></li>
<li><strong>Often very efficient</strong> (polynomial time)</li>
<li><strong>Intuitive approach</strong> for many problems</li>
<li><strong>Memory efficient</strong> (usually requires minimal storage)</li></ol>
</section>

            <section class="content-section" id="limitations">
                <h3 class="section-heading"><strong>Limitations</strong></h3>
            
<ol class="content-list"><li><strong>Doesn't always yield optimal solutions</strong></li>
<li><strong>Difficult to prove correctness</strong></li>
<li><strong>Not applicable to all problems</strong></li>
<li><strong>Local optima may not lead to global optimum</strong></li></ol>
</section>

            <section class="content-section" id="when-greedy-fails">
                <h3 class="section-heading"><strong>When Greedy Fails</strong></h3>
            
<ul class="content-list"><li><strong>0/1 Knapsack Problem</strong>: Greedy fails, but Dynamic Programming works.</li>
<li><strong>Traveling Salesman Problem</strong>: No greedy solution gives optimal result.</li>
<li><strong>Counterexample</strong>: Sometimes a greedy choice prevents better solutions later.</li></ul>
<hr class="content-hr">
</section>

            <section class="content-section" id="2-prims-algorithm">
                <h2 class="section-heading"><strong>2. Prim's Algorithm</strong></h2>
            
</section>

            <section class="content-section" id="meaning-concept">
                <h3 class="section-heading"><strong>Meaning / Concept</strong></h3>
            
<p class="paragraph">Prim's Algorithm is a greedy algorithm for finding a <strong>Minimum Spanning Tree (MST)</strong> of a connected, undirected graph with weighted edges. It grows the MST one vertex at a time, always adding the cheapest edge connecting a vertex in the MST to a vertex outside it.</p>
</section>

            <section class="content-section" id="formal-definition">
                <h3 class="section-heading"><strong>Formal Definition</strong></h3>
            
<p class="paragraph">Given a connected, undirected graph G = (V, E) with weight function w: E → ℝ, find an acyclic subset T ⊆ E that connects all vertices and whose total weight w(T) = Σ w(u,v) is minimized.</p>
</section>

            <section class="content-section" id="algorithm-step-by-step">
                <h3 class="section-heading"><strong>Algorithm (Step-by-Step)</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">Algorithm Prim(G, w)
// Input: Connected weighted graph G = (V, E) with weight function w
// Output: Set of edges composing an MST
Initialize tree with a single vertex, chosen arbitrarily from V
Initialize priority queue Q with all vertices not in tree
For each vertex v in Q, key[v] ← ∞, parent[v] ← null
key[start] ← 0  // Start with any vertex

while Q is not empty do
    u ← Extract-Min(Q)  // Vertex with minimum key
    for each vertex v adjacent to u do
        if v ∈ Q and w(u, v) &lt; key[v] then
            parent[v] ← u
            key[v] ← w(u, v)
            Decrease-Key(Q, v, key[v])
            
// Construct MST from parent pointers
T ← ∅
for each vertex v ≠ start do
    T ← T ∪ {(parent[v], v)}
return T</code></pre>
            </div>
            
</section>

            <section class="content-section" id="explanation-of-the-algorithm">
                <h3 class="section-heading"><strong>Explanation of the Algorithm</strong></h3>
            
<ol class="content-list"><li><strong>Initialization</strong>: Start with any vertex, mark it as part of MST.</li>
<li><strong>Main Loop</strong>: Repeatedly add the cheapest edge that connects a vertex in MST to a vertex outside MST.</li>
<li><strong>Key Maintenance</strong>: For each vertex not in MST, maintain the minimum weight edge connecting it to MST.</li>
<li><strong>Priority Queue</strong>: Efficiently selects next vertex to add.</li>
<li><strong>Completion</strong>: When all vertices are in MST, algorithm terminates.</li></ol>
</section>

            <section class="content-section" id="example-problem-with-working-steps">
                <h3 class="section-heading"><strong>Example Problem with Working Steps</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">        B
     4/   \3
     /     \
    A---2---C
     \     /
     5\   /6
        D</code></pre>
            </div>
            
<p class="paragraph"><strong>Problem</strong>: Find MST for this graph:
Vertices: A, B, C, D
Edges: (A,B)=4, (A,C)=2, (A,D)=5, (B,C)=3, (C,D)=6</p>
<p class="paragraph"><strong>Step-by-step execution starting from A</strong>:</p>
<ul class="content-list"><li>Key[A] = 0, others = ∞</li>
<li>Q = {B(∞), C(∞), D(∞)}</li></ul>
<p class="paragraph"><strong>Step 1</strong>: Start with A in MST</p>
<ul class="content-list"><li>B: 4 < ∞ → key[B] = 4, parent[B] = A</li>
<li>C: 2 < ∞ → key[C] = 2, parent[C] = A</li>
<li>D: 5 < ∞ → key[D] = 5, parent[D] = A</li>
<li>Extract min from Q: C (key=2)</li>
<li>Add edge (A,C) to MST</li></ul>
<p class="paragraph"><strong>Step 2</strong>: Process A's neighbors:</p>
<ul class="content-list"><li>B: w(C,B)=3 < key[B]=4 → key[B] = 3, parent[B] = C</li>
<li>D: w(C,D)=6 > key[D]=5 → no change</li>
<li>Extract min from Q: B (key=3)</li>
<li>Add edge (C,B) to MST</li></ul>
<p class="paragraph"><strong>Step 3</strong>: Process C's neighbors (B, D):</p>
<ul class="content-list"><li>A: already in MST</li>
<li>C: already in MST</li>
<li>D: no direct edge</li>
<li>Extract min from Q: D (key=5)</li>
<li>Add edge (A,D) to MST</li></ul>
<p class="paragraph"><strong>Step 4</strong>: Process B's neighbors:</p>
<p class="paragraph"><strong>MST Edges</strong>: (A,C), (C,B), (A,D)
<strong>Total weight</strong>: 2 + 3 + 5 = 10</p>
</section>

            <section class="content-section" id="time-complexity">
                <h3 class="section-heading"><strong>Time Complexity</strong></h3>
            
<ul class="content-list"><li><strong>Using Binary Heap</strong>: O(E log V)</li>
<li><strong>Using Fibonacci Heap</strong>: O(E + V log V)</li>
<li><strong>Using Adjacency Matrix</strong>: O(V²)</li></ul>
<p class="paragraph">Where: V = vertices, E = edges</p>
</section>

            <section class="content-section" id="space-complexity">
                <h3 class="section-heading"><strong>Space Complexity</strong></h3>
            
<p class="paragraph">O(V + E) - To store graph and auxiliary data structures.</p>
</section>

            <section class="content-section" id="proof-of-correctness">
                <h3 class="section-heading"><strong>Proof of Correctness</strong></h3>
            
<p class="paragraph"><strong>Greedy Choice Property</strong>: The edge with smallest weight connecting MST to outside is always in some MST.</p>
<p class="paragraph"><strong>Cut Property</strong>: For any cut of the graph, the minimum weight edge crossing the cut is in some MST. Prim's algorithm always chooses such edges.</p>
</section>

            <section class="content-section" id="characteristics">
                <h3 class="section-heading"><strong>Characteristics</strong></h3>
            
<ol class="content-list"><li><strong>Greedy algorithm</strong> for MST</li>
<li><strong>Works on connected graphs only</strong></li>
<li><strong>Produces tree</strong> (acyclic, connected, V-1 edges)</li>
<li><strong>Not unique</strong> - Graph may have multiple MSTs</li></ol>
</section>

            <section class="content-section" id="applications">
                <h3 class="section-heading"><strong>Applications</strong></h3>
            
<ol class="content-list"><li>Network design (telephone, computer, road)</li>
<li>Cluster analysis</li>
<li>Image segmentation</li>
<li>Approximation algorithms for NP-hard problems</li></ol>
<hr class="content-hr">
</section>

            <section class="content-section" id="3-kruskals-algorithm">
                <h2 class="section-heading"><strong>3. Kruskal's Algorithm</strong></h2>
            
</section>

            <section class="content-section" id="meaning-concept">
                <h3 class="section-heading"><strong>Meaning / Concept</strong></h3>
            
<p class="paragraph">Kruskal's Algorithm is another greedy algorithm for finding MST. It works by sorting all edges by weight and adding them one by one to the growing forest, skipping edges that would create cycles.</p>
</section>

            <section class="content-section" id="algorithm-step-by-step">
                <h3 class="section-heading"><strong>Algorithm (Step-by-Step)</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">Algorithm Kruskal(G, w)
// Input: Weighted connected graph G = (V, E) with weight function w
// Output: Set of edges composing an MST
Sort edges in E into nondecreasing order by weight w
T ← ∅  // Will contain edges of MST
Initialize disjoint-set data structure with each vertex as separate set

for each edge (u, v) in sorted order do
    if Find-Set(u) ≠ Find-Set(v) then  // u and v in different components
        T ← T ∪ {(u, v)}
        Union(u, v)  // Merge components
        
    if |T| = |V| - 1 then break  // Tree complete
    
return T</code></pre>
            </div>
            
</section>

            <section class="content-section" id="explanation-of-the-algorithm">
                <h3 class="section-heading"><strong>Explanation of the Algorithm</strong></h3>
            
<ol class="content-list"><li><strong>Sort edges</strong> in ascending order of weight.</li>
<li><strong>Initialize</strong> each vertex as its own component (using disjoint-set/union-find).</li>
<li><strong>Process edges</strong> in sorted order:</li></ol>
<ol class="content-list"><li><strong>Stop</strong> when MST has V-1 edges.</li></ol>
<p class="paragraph">- If edge connects different components, add it to MST and merge components.
   - If edge connects vertices in same component, skip it (would create cycle).</p>
</section>

            <section class="content-section" id="example-problem-with-working-steps">
                <h3 class="section-heading"><strong>Example Problem with Working Steps</strong></h3>
            
<p class="paragraph"><strong>Problem</strong>: Same graph as Prim's example:
Edges sorted: (A,C)=2, (B,C)=3, (A,B)=4, (A,D)=5, (C,D)=6</p>
<p class="paragraph"><strong>Initial</strong>: Each vertex in own set: {A}, {B}, {C}, {D}</p>
<ul class="content-list"><li>Find(A) ≠ Find(C) → Add to MST</li>
<li>Union A and C: {A,C}, {B}, {D}</li>
<li>MST edges: {(A,C)}</li></ul>
<p class="paragraph"><strong>Step 1</strong>: Edge (A,C)=2</p>
<ul class="content-list"><li>Find(B) ≠ Find(C) → Add to MST</li>
<li>Union B with {A,C}: {A,B,C}, {D}</li>
<li>MST edges: {(A,C), (B,C)}</li></ul>
<p class="paragraph"><strong>Step 2</strong>: Edge (B,C)=3</p>
<ul class="content-list"><li>Find(A) = Find(B) → Skip (would create cycle)</li></ul>
<p class="paragraph"><strong>Step 3</strong>: Edge (A,B)=4</p>
<ul class="content-list"><li>Find(A) ≠ Find(D) → Add to MST</li>
<li>Union D with {A,B,C}: {A,B,C,D}</li>
<li>MST edges: {(A,C), (B,C), (A,D)}</li></ul>
<p class="paragraph"><strong>Step 4</strong>: Edge (A,D)=5</p>
<p class="paragraph"><strong>Step 5</strong>: Have V-1=3 edges, algorithm stops
<strong>Total weight</strong>: 2 + 3 + 5 = 10</p>
</section>

            <section class="content-section" id="time-complexity">
                <h3 class="section-heading"><strong>Time Complexity</strong></h3>
            
<ul class="content-list"><li><strong>Sorting edges</strong>: O(E log E) = O(E log V) since E ≤ V²</li>
<li><strong>Union-Find operations</strong>: O(E α(V)) where α is inverse Ackermann (almost constant)</li>
<li><strong>Total</strong>: O(E log V)</li></ul>
</section>

            <section class="content-section" id="space-complexity">
                <h3 class="section-heading"><strong>Space Complexity</strong></h3>
            
<p class="paragraph">O(V + E) - For storing graph and union-find structure.</p>
</section>

            <section class="content-section" id="proof-of-correctness">
                <h3 class="section-heading"><strong>Proof of Correctness</strong></h3>
            
<p class="paragraph"><strong>Greedy Choice Property</strong>: The algorithm always picks the smallest available edge that doesn't create a cycle, which is always part of some MST (by Cut Property).</p>
<p class="paragraph"><strong>Cycle Property</strong>: For any cycle in the graph, the heaviest edge is not in any MST. Kruskal never picks edges that create cycles.</p>
</section>

            <section class="content-section" id="comparison-prim-vs-kruskal">
                <h3 class="section-heading"><strong>Comparison: Prim vs Kruskal</strong></h3>
            
<p class="paragraph">| Aspect | Prim's Algorithm | Kruskal's Algorithm |
|--------|-----------------|-------------------|
| <strong>Approach</strong> | Vertex-based | Edge-based |
| <strong>Best for</strong> | Dense graphs (E ≈ V²) | Sparse graphs (E ≈ V) |
| <strong>Data Structure</strong> | Priority Queue | Union-Find + Sorting |
| <strong>Time Complexity</strong> | O(V²) or O(E log V) | O(E log V) |
| <strong>When to Use</strong> | Graph represented as matrix | Graph represented as edge list |</p>
</section>

            <section class="content-section" id="applications">
                <h3 class="section-heading"><strong>Applications</strong></h3>
            
<ol class="content-list"><li>Electrical wiring layout</li>
<li>Computer network design</li>
<li>Transportation network planning</li>
<li>Circuit design</li></ol>
<hr class="content-hr">
</section>

            <section class="content-section" id="4-dijkstras-algorithm">
                <h2 class="section-heading"><strong>4. Dijkstra's Algorithm</strong></h2>
            
</section>

            <section class="content-section" id="meaning-concept">
                <h3 class="section-heading"><strong>Meaning / Concept</strong></h3>
            
<p class="paragraph">Dijkstra's Algorithm is a greedy algorithm for finding the shortest paths from a single source vertex to all other vertices in a graph with <strong>non-negative</strong> edge weights.</p>
</section>

            <section class="content-section" id="formal-definition">
                <h3 class="section-heading"><strong>Formal Definition</strong></h3>
            
<p class="paragraph">Given a directed or undirected graph G = (V, E) with non-negative weight function w: E → ℝ⁺, and a source vertex s, find the shortest path from s to every vertex v ∈ V.</p>
</section>

            <section class="content-section" id="algorithm-step-by-step">
                <h3 class="section-heading"><strong>Algorithm (Step-by-Step)</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">Algorithm Dijkstra(G, w, s)
// Input: Graph G = (V, E) with non-negative weights w, source vertex s
// Output: For all vertices v, distance d[v] (shortest from s) and predecessor p[v]
Initialize-Single-Source(G, s)
S ← ∅  // Set of vertices whose shortest path is known
Q ← V  // Priority queue of vertices

while Q ≠ ∅ do
    u ← Extract-Min(Q)  // Vertex with smallest distance estimate
    S ← S ∪ {u}
    for each vertex v adjacent to u do
        Relax(u, v, w)
        
Procedure Initialize-Single-Source(G, s)
for each vertex v ∈ V do
    d[v] ← ∞
    p[v] ← null
d[s] ← 0

Procedure Relax(u, v, w)
if d[v] &gt; d[u] + w(u, v) then
    d[v] ← d[u] + w(u, v)
    p[v] ← u</code></pre>
            </div>
            
</section>

            <section class="content-section" id="explanation-of-the-algorithm">
                <h3 class="section-heading"><strong>Explanation of the Algorithm</strong></h3>
            
<ol class="content-list"><li><strong>Initialization</strong>: Set distance to source as 0, all others as ∞.</li>
<li><strong>Main Loop</strong>: Repeatedly select vertex with smallest known distance.</li>
<li><strong>Relaxation</strong>: For selected vertex, update distances to its neighbors if a shorter path is found.</li>
<li><strong>Mark vertex</strong>: Once processed, its shortest distance is finalized.</li>
<li><strong>Continue</strong> until all vertices processed.</li></ol>
</section>

            <section class="content-section" id="example-problem-with-working-steps">
                <h3 class="section-heading"><strong>Example Problem with Working Steps</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">        B
     1/   \4
     /     \
    A---3---C
     \     /
     5\   /2
        D</code></pre>
            </div>
            
<p class="paragraph"><strong>Problem</strong>: Find shortest paths from A to all vertices:
Edges: (A,B)=1, (A,C)=3, (A,D)=5, (B,C)=4, (C,D)=2</p>
<p class="paragraph"><strong>Step-by-step execution</strong>:</p>
<p class="paragraph"><strong>Initial</strong>: d[A]=0, d[B]=∞, d[C]=∞, d[D]=∞
S = {}, Q = {A(0), B(∞), C(∞), D(∞)}</p>
<ul class="content-list"><li>Relax neighbors:</li></ul>
<p class="paragraph"><strong>Step 1</strong>: Extract A (min distance 0)
  - B: 0+1=1 < ∞ → d[B]=1, p[B]=A
  - C: 0+3=3 < ∞ → d[C]=3, p[C]=A
  - D: 0+5=5 < ∞ → d[D]=5, p[D]=A
S = {A}, Q = {B(1), C(3), D(5)}</p>
<ul class="content-list"><li>Relax B's neighbors:</li></ul>
<p class="paragraph"><strong>Step 2</strong>: Extract B (distance 1)
  - C: 1+4=5 > d[C]=3 → no change
  - D: no direct edge
S = {A,B}, Q = {C(3), D(5)}</p>
<ul class="content-list"><li>Relax C's neighbors:</li></ul>
<p class="paragraph"><strong>Step 3</strong>: Extract C (distance 3)
  - D: 3+2=5 = d[D]=5 → no change (or update with same distance)
S = {A,B,C}, Q = {D(5)}</p>
<ul class="content-list"><li>No unprocessed neighbors</li></ul>
<p class="paragraph"><strong>Step 4</strong>: Extract D (distance 5)
S = {A,B,C,D}, Q = {}</p>
<ul class="content-list"><li>A: 0</li>
<li>B: 1 (path: A→B)</li>
<li>C: 3 (path: A→C)</li>
<li>D: 5 (paths: A→D or A→C→D)</li></ul>
<p class="paragraph"><strong>Final distances from A</strong>:</p>
</section>

            <section class="content-section" id="time-complexity">
                <h3 class="section-heading"><strong>Time Complexity</strong></h3>
            
<ul class="content-list"><li><strong>Using Array</strong>: O(V²)</li>
<li><strong>Using Binary Heap</strong>: O((V+E) log V)</li>
<li><strong>Using Fibonacci Heap</strong>: O(V log V + E)</li></ul>
</section>

            <section class="content-section" id="space-complexity">
                <h3 class="section-heading"><strong>Space Complexity</strong></h3>
            
<p class="paragraph">O(V + E) - For graph representation and distance arrays.</p>
</section>

            <section class="content-section" id="proof-of-correctness">
                <h3 class="section-heading"><strong>Proof of Correctness</strong></h3>
            
<p class="paragraph"><strong>Greedy Choice Property</strong>: At each step, the vertex with minimum distance estimate has its shortest path already determined.</p>
<p class="paragraph"><strong>Invariant</strong>: For each vertex v ∈ S, d[v] is the length of shortest path from s to v.</p>
</section>

            <section class="content-section" id="characteristics">
                <h3 class="section-heading"><strong>Characteristics</strong></h3>
            
<ol class="content-list"><li><strong>Only works with non-negative edge weights</strong></li>
<li><strong>Finds shortest paths to all vertices</strong></li>
<li><strong>Greedy algorithm</strong></li>
<li><strong>Not suitable for graphs with negative weights</strong> (use Bellman-Ford instead)</li></ol>
</section>

            <section class="content-section" id="limitations">
                <h3 class="section-heading"><strong>Limitations</strong></h3>
            
<ol class="content-list"><li><strong>Cannot handle negative weight edges</strong> (fails if negative cycles exist)</li>
<li><strong>Not the most efficient</strong> for single-pair shortest path (use A* for that)</li>
<li><strong>Requires priority queue</strong> for efficiency</li></ol>
</section>

            <section class="content-section" id="applications">
                <h3 class="section-heading"><strong>Applications</strong></h3>
            
<ol class="content-list"><li><strong>GPS navigation systems</strong></li>
<li><strong>Network routing protocols</strong> (OSPF, IS-IS)</li>
<li><strong>Social network analysis</strong> (degrees of separation)</li>
<li><strong>Robot path planning</strong></li>
<li><strong>Flight itinerary planning</strong></li></ol>
<hr class="content-hr">
</section>

            <section class="content-section" id="5-lower-bound-arguments">
                <h2 class="section-heading"><strong>5. Lower-Bound Arguments</strong></h2>
            
</section>

            <section class="content-section" id="meaning-concept">
                <h3 class="section-heading"><strong>Meaning / Concept</strong></h3>
            
<p class="paragraph">Lower-bound arguments establish the minimum amount of resources (time, space, comparisons) required to solve a problem, regardless of the algorithm used.</p>
</section>

            <section class="content-section" id="formal-definition">
                <h3 class="section-heading"><strong>Formal Definition</strong></h3>
            
<p class="paragraph">A <strong>lower bound</strong> L(n) is a function that bounds from below the complexity of any algorithm that solves a given problem. For any algorithm A solving problem P, Time(A) ≥ L(n) for all inputs of size n.</p>
</section>

            <section class="content-section" id="need-purpose">
                <h3 class="section-heading"><strong>Need / Purpose</strong></h3>
            
<ol class="content-list"><li><strong>Establish problem difficulty</strong>: Show a problem is inherently hard.</li>
<li><strong>Guide algorithm design</strong>: If lower bound matches upper bound, algorithm is optimal.</li>
<li><strong>Compare algorithms</strong>: Know when further improvement is impossible.</li>
<li><strong>Complexity classification</strong>: Place problems in complexity classes.</li></ol>
</section>

            <section class="content-section" id="methods-for-proving-lower-bounds">
                <h3 class="section-heading"><strong>Methods for Proving Lower Bounds</strong></h3>
            
</section>

            <section class="content-section" id="1-trivial-lower-bounds">
                <h4 class="section-heading"><strong>1. Trivial Lower Bounds</strong></h4>
            
<ul class="content-list"><li><strong>Example</strong>: Any algorithm that reads all n input items takes Ω(n) time.</li>
<li><strong>Example</strong>: Any algorithm that generates all 2ⁿ subsets takes Ω(2ⁿ) time.</li></ul>
<p class="paragraph">Based on input/output size.</p>
</section>

            <section class="content-section" id="2-information-theoretic-arguments">
                <h4 class="section-heading"><strong>2. Information-Theoretic Arguments</strong></h4>
            
<ul class="content-list"><li><strong>Example</strong>: Sorting n items requires Ω(n log n) comparisons because there are n! possible permutations and each comparison yields 1 bit of information.</li>
<li><strong>Number of leaves in decision tree ≥ number of possible outputs</strong>.</li></ul>
<p class="paragraph">Based on amount of information needed.</p>
</section>

            <section class="content-section" id="3-adversary-arguments">
                <h4 class="section-heading"><strong>3. Adversary Arguments</strong></h4>
            
<ul class="content-list"><li><strong>Example</strong>: For searching in unsorted array, adversary can always place key in last checked position, requiring Ω(n) comparisons.</li>
<li><strong>Example</strong>: For finding max/min, need n-1 comparisons (Ω(n)).</li></ul>
<p class="paragraph">An adversary provides worst-case input based on algorithm's choices.</p>
</section>

            <section class="content-section" id="4-problem-reduction">
                <h4 class="section-heading"><strong>4. Problem Reduction</strong></h4>
            
<ul class="content-list"><li><strong>Example</strong>: Convex hull requires Ω(n log n) because sorting reduces to it.</li></ul>
<p class="paragraph">If problem A is at least as hard as problem B, and B has lower bound L(n), then A has lower bound at least L(n).</p>
</section>

            <section class="content-section" id="5-algebraic-and-combinatorial-arguments">
                <h4 class="section-heading"><strong>5. Algebraic and Combinatorial Arguments</strong></h4>
            
<ul class="content-list"><li><strong>Example</strong>: Algebraic decision trees for element uniqueness require Ω(n log n).</li></ul>
<p class="paragraph">Using mathematical properties.</p>
</section>

            <section class="content-section" id="example-sorting-lower-bound">
                <h3 class="section-heading"><strong>Example: Sorting Lower Bound</strong></h3>
            
<p class="paragraph"><strong>Theorem</strong>: Any comparison-based sorting algorithm requires Ω(n log n) comparisons in worst case.</p>
<ol class="content-list"><li>There are n! possible permutations of n items.</li>
<li>Each comparison has 2 outcomes (< or >).</li>
<li>Decision tree must have at least n! leaves.</li>
<li>Height h of binary tree with L leaves: h ≥ ⌈log₂ L⌉.</li>
<li>Thus, h ≥ ⌈log₂(n!)⌉ ≈ n log₂ n - 1.44n = Ω(n log n).</li></ol>
<p class="paragraph"><strong>Proof (Information-theoretic)</strong>:</p>
</section>

            <section class="content-section" id="example-searching-lower-bound">
                <h3 class="section-heading"><strong>Example: Searching Lower Bound</strong></h3>
            
<p class="paragraph"><strong>Sorted array search</strong>: Binary search is optimal with Θ(log n) comparisons.
<strong>Proof</strong>: Decision tree argument - n items in sorted array need ⌈log₂(n+1)⌉ comparisons.</p>
</section>

            <section class="content-section" id="significance-in-algorithm-design">
                <h3 class="section-heading"><strong>Significance in Algorithm Design</strong></h3>
            
<ol class="content-list"><li><strong>Optimality proof</strong>: If algorithm matches lower bound, it's optimal.</li>
<li><strong>Research direction</strong>: Guides efforts - either find better algorithm or prove stronger lower bound.</li>
<li><strong>Problem classification</strong>: Distinguishes tractable from intractable.</li></ol>
<hr class="content-hr">
</section>

            <section class="content-section" id="6-decision-trees">
                <h2 class="section-heading"><strong>6. Decision Trees</strong></h2>
            
</section>

            <section class="content-section" id="meaning-concept">
                <h3 class="section-heading"><strong>Meaning / Concept</strong></h3>
            
<p class="paragraph">A decision tree is a model of computation used to analyze comparison-based algorithms. It represents the sequence of comparisons an algorithm makes and the resulting outcomes.</p>
</section>

            <section class="content-section" id="formal-definition">
                <h3 class="section-heading"><strong>Formal Definition</strong></h3>
            
<ul class="content-list"><li><strong>Internal nodes</strong>: Represent comparisons (e.g., "aᵢ < aⱼ?")</li>
<li><strong>Leaves</strong>: Represent outcomes or results</li>
<li><strong>Edges</strong>: Represent outcomes of comparisons (e.g., "yes" or "no")</li></ul>
<p class="paragraph">A decision tree is a full binary tree that represents comparisons between elements performed by an algorithm:</p>
</section>

            <section class="content-section" id="structure">
                <h3 class="section-heading"><strong>Structure</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">        [i:j]
        /   \
    &lt;       ≥
   /         \
[left subtree] [right subtree]</code></pre>
            </div>
            
</section>

            <section class="content-section" id="properties">
                <h3 class="section-heading"><strong>Properties</strong></h3>
            
<ol class="content-list"><li><strong>Height of tree</strong> = Worst-case number of comparisons</li>
<li><strong>Number of leaves</strong> ≥ Number of possible outcomes</li>
<li><strong>For sorting n elements</strong>: Leaves ≥ n!</li>
<li><strong>For searching n elements</strong>: Leaves ≥ n+1 (found at any position + not found)</li></ol>
</section>

            <section class="content-section" id="analysis-of-sorting-algorithms">
                <h3 class="section-heading"><strong>Analysis of Sorting Algorithms</strong></h3>
            
<p class="paragraph"><strong>Theorem</strong>: Any comparison-based sorting algorithm requires Ω(n log n) comparisons.</p>
<ol class="content-list"><li>There are n! possible permutations (inputs).</li>
<li>Each leaf must correspond to at least one permutation.</li>
<li>A binary tree of height h has at most 2ʰ leaves.</li>
<li>Thus, 2ʰ ≥ n!</li>
<li>Taking logs: h ≥ log₂(n!) ≈ n log₂ n (by Stirling's approximation)</li>
<li>Therefore, h = Ω(n log n)</li></ol>
<p class="paragraph"><strong>Proof using Decision Trees</strong>:</p>
</section>

            <section class="content-section" id="analysis-of-searching-algorithms">
                <h3 class="section-heading"><strong>Analysis of Searching Algorithms</strong></h3>
            
<ul class="content-list"><li>n elements in sorted array</li>
<li>Possible outcomes: element found at position i (1≤i≤n) or not found</li>
<li>Total outcomes: n+1</li>
<li>Height h: 2ʰ ≥ n+1 ⇒ h ≥ ⌈log₂(n+1)⌉</li>
<li>Binary search achieves this bound → optimal</li></ul>
<p class="paragraph"><strong>Sorted array search</strong>:</p>
</section>

            <section class="content-section" id="example-decision-tree-for-sorting-3-elements">
                <h3 class="section-heading"><strong>Example: Decision Tree for Sorting 3 Elements</strong></h3>
            

            <div class="code-block">
                <pre><code class="language-text">            a:b
           /   \
        &lt;       ≥
       /         \
     b:c          a:c
    /   \        /   \
  &lt;     ≥      &lt;     ≥
 /       \    /       \
a,b,c   a:c  b,c,a   b:a
       /   \        /   \
     &lt;     ≥      &lt;     ≥
    /       \    /       \
 a,c,b   c,a,b b,a,c   c,b,a</code></pre>
            </div>
            
<p class="paragraph">Elements: a, b, c
Height = 3 comparisons in worst case.</p>
</section>

            <section class="content-section" id="applications">
                <h3 class="section-heading"><strong>Applications</strong></h3>
            
<ol class="content-list"><li><strong>Lower bound proofs</strong> for comparison-based problems</li>
<li><strong>Algorithm analysis</strong> tool</li>
<li><strong>Machine learning</strong> (classification trees)</li>
<li><strong>Game theory</strong> (game trees)</li></ol>
</section>

            <section class="content-section" id="limitations">
                <h3 class="section-heading"><strong>Limitations</strong></h3>
            
<ol class="content-list"><li><strong>Only models comparison-based algorithms</strong></li>
<li><strong>Ignores other operations</strong> (arithmetic, data movement)</li>
<li><strong>Assumes comparisons are only source of information</strong></li></ol>
<hr class="content-hr">
</section>

            <section class="content-section" id="7-p-problems">
                <h2 class="section-heading"><strong>7. P Problems</strong></h2>
            
</section>

            <section class="content-section" id="meaning-concept">
                <h3 class="section-heading"><strong>Meaning / Concept</strong></h3>
            
<p class="paragraph"><strong>P</strong> (Polynomial Time) is the class of decision problems that can be solved by a deterministic Turing machine in polynomial time.</p>
</section>

            <section class="content-section" id="formal-definition">
                <h3 class="section-heading"><strong>Formal Definition</strong></h3>
            
<p class="paragraph">P = {L | There exists a deterministic Turing machine M and a polynomial p(n) such that M decides L in time O(p(n))}</p>
</section>

            <section class="content-section" id="key-characteristics">
                <h3 class="section-heading"><strong>Key Characteristics</strong></h3>
            
<ol class="content-list"><li><strong>Polynomial time</strong>: Running time is O(nᵏ) for some constant k.</li>
<li><strong>Deterministic</strong>: No randomness or guessing.</li>
<li><strong>Decision problems</strong>: Problems with yes/no answers.</li>
<li><strong>Tractable</strong>: Considered efficiently solvable.</li></ol>
</section>

            <section class="content-section" id="examples-of-p-problems">
                <h3 class="section-heading"><strong>Examples of P Problems</strong></h3>
            
<ol class="content-list"><li><strong>Sorting</strong> (is array sorted?)</li>
<li><strong>Searching</strong> (is element in array?)</li>
<li><strong>Minimum Spanning Tree</strong> (does graph have MST of weight ≤ k?)</li>
<li><strong>Shortest Path</strong> (is there path of length ≤ k?)</li>
<li><strong>Matrix multiplication</strong></li>
<li><strong>Linear programming</strong> (in certain forms)</li></ol>
</section>

            <section class="content-section" id="why-polynomial-time">
                <h3 class="section-heading"><strong>Why Polynomial Time?</strong></h3>
            
<ul class="content-list"><li><strong>Robustness</strong>: Model-independent (Turing machine, RAM, etc.)</li>
<li><strong>Composability</strong>: Polynomial of polynomial is polynomial</li>
<li><strong>Practicality</strong>: Most polynomial algorithms are useful in practice</li>
<li><strong>Closure properties</strong>: Closed under union, intersection, complement, etc.</li></ul>
</section>

            <section class="content-section" id="significance">
                <h3 class="section-heading"><strong>Significance</strong></h3>
            
<ol class="content-list"><li><strong>Defines tractable problems</strong></li>
<li><strong>Foundation of complexity theory</strong></li>
<li><strong>Goal of algorithm design</strong>: Find polynomial algorithms</li></ol>
</section>

            <section class="content-section" id="common-misconceptions">
                <h3 class="section-heading"><strong>Common Misconceptions</strong></h3>
            
<ol class="content-list"><li><strong>Not all polynomial algorithms are practical</strong>: O(n¹⁰⁰) is polynomial but impractical.</li>
<li><strong>Not all practical problems are in P</strong>: Some have efficient heuristics but aren't provably in P.</li>
<li><strong>P includes many important problems</strong>: Most everyday computational tasks.</li></ol>
<hr class="content-hr">
</section>

            <section class="content-section" id="8-np-problems">
                <h2 class="section-heading"><strong>8. NP Problems</strong></h2>
            
</section>

            <section class="content-section" id="meaning-concept">
                <h3 class="section-heading"><strong>Meaning / Concept</strong></h3>
            
<p class="paragraph"><strong>NP</strong> (Nondeterministic Polynomial Time) is the class of decision problems whose solutions can be <strong>verified</strong> in polynomial time by a deterministic Turing machine.</p>
</section>

            <section class="content-section" id="formal-definition">
                <h3 class="section-heading"><strong>Formal Definition</strong></h3>
            
<p class="paragraph">NP = {L | There exists a nondeterministic Turing machine M and a polynomial p(n) such that M decides L in time O(p(n))}</p>
<ul class="content-list"><li>For all x ∈ L, ∃y (|y| ≤ p(|x|) and V(x, y) accepts)</li>
<li>For all x ∉ L, ∀y (|y| ≤ p(|x|), V(x, y) rejects)</li></ul>
<p class="paragraph"><strong>Alternative Definition</strong>: L ∈ NP if there exists a polynomial-time verifier V and polynomial p such that:</p>
</section>

            <section class="content-section" id="key-characteristics">
                <h3 class="section-heading"><strong>Key Characteristics</strong></h3>
            
<ol class="content-list"><li><strong>Verification in P</strong>: Solutions can be checked quickly.</li>
<li><strong>Existence of certificate/witness</strong>: Short proof that answer is "yes".</li>
<li><strong>Nondeterministic guessing</strong>: Can "guess" solution then verify.</li>
<li><strong>Includes P</strong>: P ⊆ NP (if can solve, can certainly verify).</li></ol>
</section>

            <section class="content-section" id="examples-of-np-problems">
                <h3 class="section-heading"><strong>Examples of NP Problems</strong></h3>
            
<ol class="content-list"><li><strong>SAT</strong> (Boolean satisfiability)</li>
<li><strong>Hamiltonian Cycle</strong> (does graph have cycle visiting each vertex once?)</li>
<li><strong>Traveling Salesman</strong> (does graph have tour of length ≤ k?)</li>
<li><strong>Graph Coloring</strong> (can graph be colored with k colors?)</li>
<li><strong>Subset Sum</strong> (does subset sum to target?)</li>
<li><strong>Clique</strong> (does graph contain k-clique?)</li></ol>
</section>

            <section class="content-section" id="the-p-vs-np-question">
                <h3 class="section-heading"><strong>The P vs NP Question</strong></h3>
            
<ul class="content-list"><li><strong>P = NP?</strong>: Can every problem whose solution can be verified quickly also be solved quickly?</li>
<li><strong>Most believe P ≠ NP</strong>, but not proven.</li>
<li><strong>Clay Millennium Prize</strong>: $1 million for proof.</li></ul>
<p class="paragraph">The most famous open problem in computer science:</p>
</section>

            <section class="content-section" id="np-completeness">
                <h3 class="section-heading"><strong>NP-Completeness</strong></h3>
            
<ol class="content-list"><li>It is in NP</li>
<li>Every problem in NP can be reduced to it in polynomial time</li></ol>
<p class="paragraph">A problem is <strong>NP-complete</strong> if:</p>
</section>

            <section class="content-section" id="significance">
                <h3 class="section-heading"><strong>Significance</strong></h3>
            
<ol class="content-list"><li><strong>Captures many important practical problems</strong></li>
<li><strong>Foundation for cryptography</strong> (based on assumption P ≠ NP)</li>
<li><strong>Guides algorithm design</strong>: For NP-complete problems, seek heuristics/approximations</li></ol>
<hr class="content-hr">
</section>

            <section class="content-section" id="9-np-complete-problems">
                <h2 class="section-heading"><strong>9. NP-Complete Problems</strong></h2>
            
</section>

            <section class="content-section" id="meaning-concept">
                <h3 class="section-heading"><strong>Meaning / Concept</strong></h3>
            
<p class="paragraph"><strong>NP-Complete</strong> problems are the hardest problems in NP. If any NP-complete problem can be solved in polynomial time, then all problems in NP can be solved in polynomial time (P = NP).</p>
</section>

            <section class="content-section" id="formal-definition">
                <h3 class="section-heading"><strong>Formal Definition</strong></h3>
            
<ol class="content-list"><li><strong>L ∈ NP</strong></li>
<li><strong>L is NP-hard</strong>: For every problem L' ∈ NP, L' ≤ₚ L (polynomial-time reducible to L)</li></ol>
<p class="paragraph">A problem L is NP-complete if:</p>
</section>

            <section class="content-section" id="key-characteristics">
                <h3 class="section-heading"><strong>Key Characteristics</strong></h3>
            
<ol class="content-list"><li><strong>Hardest in NP</strong>: At least as hard as every problem in NP.</li>
<li><strong>Polynomial equivalence</strong>: All NP-complete problems are polynomially equivalent.</li>
<li><strong>Verifiable but not (known to be) solvable in P</strong>.</li>
<li><strong>Existence of one polynomial algorithm implies P = NP</strong>.</li></ol>
</section>

            <section class="content-section" id="cook-levin-theorem-1971">
                <h3 class="section-heading"><strong>Cook-Levin Theorem (1971)</strong></h3>
            
<p class="paragraph"><strong>Theorem</strong>: SAT (Boolean satisfiability) is NP-complete.
<strong>Proof</strong>: Shows every problem in NP can be reduced to SAT in polynomial time.
<strong>Significance</strong>: First proof of NP-completeness, foundation of theory.</p>
</section>

            <section class="content-section" id="examples-of-np-complete-problems">
                <h3 class="section-heading"><strong>Examples of NP-Complete Problems</strong></h3>
            
<ol class="content-list"><li><strong>SAT</strong> (Boolean satisfiability) - First proven NP-complete</li>
<li><strong>3-SAT</strong> (3-CNF satisfiability)</li>
<li><strong>Hamiltonian Cycle</strong></li>
<li><strong>Traveling Salesman Problem (decision version)</strong></li>
<li><strong>Graph Coloring</strong></li>
<li><strong>Clique Problem</strong></li>
<li><strong>Vertex Cover</strong></li>
<li><strong>Subset Sum</strong></li>
<li><strong>Knapsack (decision version)</strong></li>
<li><strong>Partition Problem</strong></li></ol>
</section>

            <section class="content-section" id="proving-np-completeness">
                <h3 class="section-heading"><strong>Proving NP-Completeness</strong></h3>
            
<ol class="content-list"><li><strong>Show L ∈ NP</strong>: Provide polynomial-time verifier.</li>
<li><strong>Choose known NP-complete problem L'</strong>.</li>
<li><strong>Show L' ≤ₚ L</strong>: Polynomial-time reduction from L' to L.</li>
<li><strong>Conclude</strong>: Since L' is NP-complete and reduces to L, L is NP-hard.</li></ol>
<p class="paragraph">To prove problem L is NP-complete:</p>
</section>

            <section class="content-section" id="example-proof-sketch-3-sat-is-np-complete">
                <h3 class="section-heading"><strong>Example Proof Sketch: 3-SAT is NP-Complete</strong></h3>
            
<ol class="content-list"><li><strong>3-SAT ∈ NP</strong>: Given assignment, can verify in O(n) time.</li>
<li><strong>SAT ≤ₚ 3-SAT</strong>: Convert any SAT formula to 3-CNF:</li></ol>
<ol class="content-list"><li><strong>Conclusion</strong>: 3-SAT is NP-complete.</li></ol>
<p class="paragraph">- Replace clause (x₁ ∨ x₂ ∨ ... ∨ xₖ) with equivalent 3-CNF formula
   - Polynomial-time transformation</p>
</section>

            <section class="content-section" id="coping-with-np-complete-problems">
                <h3 class="section-heading"><strong>Coping with NP-Complete Problems</strong></h3>
            
<p class="paragraph">Since no polynomial algorithms known (assuming P ≠ NP):</p>
</section>

            <section class="content-section" id="1-exact-algorithms-for-small-instances">
                <h4 class="section-heading"><strong>1. Exact Algorithms for Small Instances</strong></h4>
            
<ul class="content-list"><li><strong>Backtracking</strong></li>
<li><strong>Branch and Bound</strong></li>
<li><strong>Dynamic Programming</strong> (pseudopolynomial for some problems)</li></ul>
</section>

            <section class="content-section" id="2-approximation-algorithms">
                <h4 class="section-heading"><strong>2. Approximation Algorithms</strong></h4>
            
<ul class="content-list"><li><strong>Example</strong>: 2-approximation for Vertex Cover</li>
<li><strong>Example</strong>: Christofides algorithm for TSP (1.5-approximation for metric TSP)</li></ul>
<p class="paragraph">Find solution within factor of optimal.</p>
</section>

            <section class="content-section" id="3-heuristics-and-metaheuristics">
                <h4 class="section-heading"><strong>3. Heuristics and Metaheuristics</strong></h4>
            
<ul class="content-list"><li><strong>Genetic algorithms</strong></li>
<li><strong>Simulated annealing</strong></li>
<li><strong>Tabu search</strong></li>
<li><strong>Ant colony optimization</strong></li></ul>
</section>

            <section class="content-section" id="4-special-cases">
                <h4 class="section-heading"><strong>4. Special Cases</strong></h4>
            
<ul class="content-list"><li><strong>2-SAT</strong> is in P (not 3-SAT)</li>
<li><strong>Planar graphs</strong> have polynomial algorithms for some problems</li>
<li><strong>Fixed parameter tractability</strong></li></ul>
<p class="paragraph">Some restrictions make problems polynomial:</p>
</section>

            <section class="content-section" id="importance-in-practice">
                <h3 class="section-heading"><strong>Importance in Practice</strong></h3>
            
<ol class="content-list"><li><strong>Indicates problem difficulty</strong>: Tells when to seek heuristics.</li>
<li><strong>Guides algorithm design</strong>: Focus on approximation or special cases.</li>
<li><strong>Cryptography foundation</strong>: Security relies on NP-hard problems.</li>
<li><strong>Computational limits</strong>: Shows inherent limits of computation.</li></ol>
<hr class="content-hr">
</section>

            <section class="content-section" id="10-challenges-of-numerical-algorithms">
                <h2 class="section-heading"><strong>10. Challenges of Numerical Algorithms</strong></h2>
            
</section>

            <section class="content-section" id="meaning-concept">
                <h3 class="section-heading"><strong>Meaning / Concept</strong></h3>
            
<p class="paragraph">Numerical algorithms deal with continuous mathematical problems using discrete computations. They face unique challenges due to finite precision arithmetic, rounding errors, and stability issues.</p>
</section>

            <section class="content-section" id="key-challenges">
                <h3 class="section-heading"><strong>Key Challenges</strong></h3>
            
</section>

            <section class="content-section" id="1-rounding-errors">
                <h4 class="section-heading"><strong>1. Rounding Errors</strong></h4>
            
<ul class="content-list"><li><strong>Cause</strong>: Finite representation of real numbers (floating-point)</li>
<li><strong>Impact</strong>: Accumulated errors can make results meaningless</li>
<li><strong>Example</strong>: Adding many small numbers to a large number</li></ul>

            <div class="code-block">
                <pre><code class="language-python"># Catastrophic cancellation example
a = 1.000000000000001
b = 1.000000000000000
result = a - b  # Should be 0.000000000000001
# May get 0 due to limited precision</code></pre>
            </div>
            
</section>

            <section class="content-section" id="2-ill-conditioned-problems">
                <h4 class="section-heading"><strong>2. Ill-Conditioned Problems</strong></h4>
            
<ul class="content-list"><li><strong>Condition number</strong>: κ = ||Δoutput||/||Δinput||</li>
<li><strong>κ >> 1</strong>: Ill-conditioned</li>
<li><strong>Example</strong>: Solving nearly singular linear systems</li></ul>
<p class="paragraph">Small changes in input cause large changes in output.</p>
</section>

            <section class="content-section" id="3-numerical-stability">
                <h4 class="section-heading"><strong>3. Numerical Stability</strong></h4>
            
<ul class="content-list"><li><strong>Stable algorithm</strong>: Small changes in input cause small changes in output</li>
<li><strong>Unstable algorithm</strong>: Small errors amplify</li>
<li><strong>Example</strong>: Gaussian elimination without pivoting (unstable)</li></ul>
<p class="paragraph">Algorithm's sensitivity to rounding errors.</p>
</section>

            <section class="content-section" id="4-convergence-issues">
                <h4 class="section-heading"><strong>4. Convergence Issues</strong></h4>
            
<ul class="content-list"><li><strong>Diverge</strong>: Fail to converge</li>
<li><strong>Converge slowly</strong>: Require many iterations</li>
<li><strong>Converge to wrong solution</strong>: Due to local minima</li></ul>
<p class="paragraph">Iterative methods may:</p>
</section>

            <section class="content-section" id="5-overflowunderflow">
                <h4 class="section-heading"><strong>5. Overflow/Underflow</strong></h4>
            
<ul class="content-list"><li><strong>Overflow</strong>: Result too large to represent</li>
<li><strong>Underflow</strong>: Result too close to zero</li>
<li><strong>Example</strong>: Computing factorial of large numbers</li></ul>
</section>

            <section class="content-section" id="6-discretization-error">
                <h4 class="section-heading"><strong>6. Discretization Error</strong></h4>
            
<ul class="content-list"><li><strong>Numerical integration</strong></li>
<li><strong>Differential equations</strong></li>
<li><strong>Example</strong>: Rectangle vs Trapezoidal rule</li></ul>
<p class="paragraph">Approximating continuous with discrete.</p>
</section>

            <section class="content-section" id="specific-problem-areas">
                <h3 class="section-heading"><strong>Specific Problem Areas</strong></h3>
            
</section>

            <section class="content-section" id="1-solving-linear-systems-ax-b">
                <h4 class="section-heading"><strong>1. Solving Linear Systems Ax = b</strong></h4>
            
<ul class="content-list"><li><strong>Direct methods</strong> (Gaussian elimination): O(n³), stability issues</li>
<li><strong>Iterative methods</strong> (Gauss-Seidel, Jacobi): Convergence issues</li>
<li><strong>Condition number problems</strong>: κ(A) large → inaccurate solutions</li></ul>
</section>

            <section class="content-section" id="2-eigenvalue-problems">
                <h4 class="section-heading"><strong>2. Eigenvalue Problems</strong></h4>
            
<ul class="content-list"><li><strong>Power method</strong>: Finds dominant eigenvalue, slow convergence</li>
<li><strong>QR algorithm</strong>: More robust but complex</li>
<li><strong>Sensitivity</strong>: Small changes can drastically change eigenvectors</li></ul>
</section>

            <section class="content-section" id="3-numerical-integration">
                <h4 class="section-heading"><strong>3. Numerical Integration</strong></h4>
            
<ul class="content-list"><li><strong>Newton-Cotes formulas</strong>: Rectangle, Trapezoidal, Simpson's rules</li>
<li><strong>Error</strong>: O(hᵏ) where h = step size</li>
<li><strong>Adaptive methods</strong>: Vary step size based on error estimate</li></ul>
</section>

            <section class="content-section" id="4-root-finding">
                <h4 class="section-heading"><strong>4. Root Finding</strong></h4>
            
<ul class="content-list"><li><strong>Bisection method</strong>: Guaranteed but slow (linear convergence)</li>
<li><strong>Newton-Raphson</strong>: Quadratic convergence but may diverge</li>
<li><strong>Secant method</strong>: Faster than bisection, no derivative needed</li></ul>
</section>

            <section class="content-section" id="5-optimization">
                <h4 class="section-heading"><strong>5. Optimization</strong></h4>
            
<ul class="content-list"><li><strong>Gradient descent</strong>: May converge slowly or to local minima</li>
<li><strong>Line search</strong>: Finding optimal step size</li>
<li><strong>Convex vs non-convex</strong>: Different challenges</li></ul>
</section>

            <section class="content-section" id="techniques-to-address-challenges">
                <h3 class="section-heading"><strong>Techniques to Address Challenges</strong></h3>
            
</section>

            <section class="content-section" id="1-error-analysis">
                <h4 class="section-heading"><strong>1. Error Analysis</strong></h4>
            
<ul class="content-list"><li><strong>Forward error analysis</strong>: Bound error in computed solution</li>
<li><strong>Backward error analysis</strong>: Show computed solution is exact for slightly perturbed problem</li>
<li><strong>Example</strong>: Wilkinson's polynomial - roots sensitive to coefficients</li></ul>
</section>

            <section class="content-section" id="2-stable-algorithms">
                <h4 class="section-heading"><strong>2. Stable Algorithms</strong></h4>
            
<ul class="content-list"><li><strong>Pivoting in Gaussian elimination</strong></li>
<li><strong>QR decomposition</strong> instead of normal equations for least squares</li>
<li><strong>Orthogonal transformations</strong> to preserve norm</li></ul>
</section>

            <section class="content-section" id="3-adaptive-methods">
                <h4 class="section-heading"><strong>3. Adaptive Methods</strong></h4>
            
<ul class="content-list"><li><strong>Adaptive quadrature</strong>: Vary step size based on function behavior</li>
<li><strong>Adaptive ODE solvers</strong>: Vary step size based on error estimate</li></ul>
</section>

            <section class="content-section" id="4-high-precision-arithmetic">
                <h4 class="section-heading"><strong>4. High-Precision Arithmetic</strong></h4>
            
<ul class="content-list"><li><strong>Multiple precision libraries</strong> (GMP, MPFR)</li>
<li><strong>Arbitrary precision</strong> when needed</li>
<li><strong>Trade-off</strong>: Speed vs accuracy</li></ul>
</section>

            <section class="content-section" id="5-condition-number-estimation">
                <h4 class="section-heading"><strong>5. Condition Number Estimation</strong></h4>
            
<ul class="content-list"><li><strong>Compute or estimate κ(A)</strong></li>
<li><strong>Warn user</strong> when problem ill-conditioned</li>
<li><strong>Regularization</strong> for ill-conditioned problems</li></ul>
</section>

            <section class="content-section" id="real-world-examples-of-numerical-challenges">
                <h3 class="section-heading"><strong>Real-world Examples of Numerical Challenges</strong></h3>
            
</section>

            <section class="content-section" id="1-ariane-5-rocket-failure-1996">
                <h4 class="section-heading"><strong>1. Ariane 5 Rocket Failure (1996)</strong></h4>
            
<ul class="content-list"><li><strong>Cause</strong>: Floating-point overflow in guidance system</li>
<li><strong>Impact</strong>: $500 million loss</li>
<li><strong>Lesson</strong>: Need rigorous numerical analysis in safety-critical systems</li></ul>
</section>

            <section class="content-section" id="2-patriot-missile-failure-1991">
                <h4 class="section-heading"><strong>2. Patriot Missile Failure (1991)</strong></h4>
            
<ul class="content-list"><li><strong>Cause</strong>: Accumulated rounding error in time calculation</li>
<li><strong>Impact</strong>: 28 deaths</li>
<li><strong>Error</strong>: 0.34 second drift over 100 hours</li></ul>
</section>

            <section class="content-section" id="3-vancouver-stock-exchange-1982">
                <h4 class="section-heading"><strong>3. Vancouver Stock Exchange (1982)</strong></h4>
            
<ul class="content-list"><li><strong>Cause</strong>: Truncation error in index calculation</li>
<li><strong>Impact</strong>: 20-point error in index over 22 months</li>
<li><strong>Lesson</strong>: Need proper rounding in financial calculations</li></ul>
</section>

            <section class="content-section" id="best-practices-for-numerical-algorithms">
                <h3 class="section-heading"><strong>Best Practices for Numerical Algorithms</strong></h3>
            
<ol class="content-list"><li><strong>Understand problem conditioning</strong></li>
<li><strong>Choose stable algorithms</strong></li>
<li><strong>Use higher precision when needed</strong></li>
<li><strong>Implement careful error handling</strong></li>
<li><strong>Validate with known test cases</strong></li>
<li><strong>Consider alternative formulations</strong></li>
<li><strong>Monitor convergence carefully</strong></li>
<li><strong>Use established numerical libraries</strong> (LAPACK, BLAS, NumPy)</li></ol>
</section>

            <section class="content-section" id="importance-for-computer-science">
                <h3 class="section-heading"><strong>Importance for Computer Science</strong></h3>
            
<ol class="content-list"><li><strong>Scientific computing</strong>: Simulations, modeling</li>
<li><strong>Computer graphics</strong>: 3D transformations, rendering</li>
<li><strong>Machine learning</strong>: Optimization, linear algebra</li>
<li><strong>Cryptography</strong>: Number-theoretic computations</li>
<li><strong>Computer vision</strong>: Image processing, geometry</li></ol>
</section>
        </main>
        
        <footer class="document-footer">
            <div class="footer-content">
                <p>Document generated on January 01, 2026 at 20:55</p>
                <p class="document-stats">43 sections • 43 code blocks</p>
            </div>
        </footer>
        
    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-javascript.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-java.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-c.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-cpp.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-sql.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-bash.min.js"></script>
    <script>
        // Smooth scrolling for TOC links
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                const targetId = this.getAttribute('href');
                if (targetId === '#') return;
                
                const targetElement = document.querySelector(targetId);
                if (targetElement) {
                    window.scrollTo({
                        top: targetElement.offsetTop - 80,
                        behavior: 'smooth'
                    });
                }
            });
        });
        
        // Copy code blocks
        document.querySelectorAll('pre code').forEach(codeBlock => {
            const copyButton = document.createElement('button');
            copyButton.className = 'copy-button';
            copyButton.innerHTML = '📋 Copy';
            copyButton.title = 'Copy to clipboard';
            
            const pre = codeBlock.parentNode;
            pre.style.position = 'relative';
            pre.insertBefore(copyButton, codeBlock);
            
            copyButton.addEventListener('click', async () => {
                try {
                    await navigator.clipboard.writeText(codeBlock.textContent);
                    copyButton.innerHTML = '✓ Copied!';
                    copyButton.classList.add('copied');
                    setTimeout(() => {
                        copyButton.innerHTML = '📋 Copy';
                        copyButton.classList.remove('copied');
                    }, 2000);
                } catch (err) {
                    console.error('Failed to copy: ', err);
                }
            });
        });
    </script>
</body>
</html>